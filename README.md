# Procesamiento del Lenguaje Natural - Challenges - CEIA - FIUBA

**Alumno:** Claudio Guillermo Barril

---

## Desaf√≠o 1: Vectorizaci√≥n y Similitud de Documentos

### üîπ Fase 1: Representaci√≥n y Similitud de Documentos

Se aplican m√©todos de vectorizaci√≥n como **Bag of Words** y **TF-IDF** para transformar los textos en vectores num√©ricos.\
Se calcula la **distancia del coseno** entre documentos para identificar pares similares.\
Esta representaci√≥n permite comparar el contenido textual de forma cuantitativa.

**Observaciones:**
> El resultado fue variado, entre documentos que resultan similares por contenido tem√°tico y de clase, y otros en los que se aprecia ruido o en los que ciertas caracter√≠sticas de los mismos complicaron la tarea (como extensas firmas en emails de reducido tama√±o).


### üîπ Fase 2: Entrenamiento de Modelo de Clasificaci√≥n

Se entrena un modelo de clasificaci√≥n **Naive Bayes** basado en las representaciones generadas.\
Finalmente, el modelo elegido tras una b√∫squeda de hiperpar√°metros, resulta ser **Complement Naive Bayes**, una variante optimizada para datos desbalanceados.

**üîé Modelo seleccionado:**
- `clf`: `ComplementNB()` ‚Üí Elegido por su robustez ante clases desbalanceadas.

**‚öôÔ∏è Par√°metros del clasificador (`clf`):**
- `clf__alpha`: `0.6374` ‚Üí Regularizaci√≥n moderada que mejora la generalizaci√≥n.
- `clf__fit_prior`: `False` ‚Üí No ajusta autom√°ticamente las probabilidades previas.

**üìù Par√°metros del vectorizador TF-IDF (`tfidf`):**
- `tfidf__max_features`: `None` ‚Üí Se usan todas las palabras disponibles.
- `tfidf__ngram_range`: `(1, 2)` ‚Üí Usa unigramas y bigramas.
- `tfidf__norm`: `'l2'` ‚Üí Normalizaci√≥n L2 aplicada.
- `tfidf__stop_words`: `'english'` ‚Üí Elimina palabras comunes del ingl√©s.
- `tfidf__sublinear_tf`: `True` ‚Üí Aplica escala logar√≠tmica a la frecuencia de t√©rminos.
- `tfidf__use_idf`: `True` ‚Üí Usa la frecuencia inversa de documentos.

### üîπ Fase 3: Vectorizaci√≥n de Matriz Transpuesta (Similitud de Palabras)

Se invierte la matriz documento-t√©rmino para analizar similitudes entre palabras (en lugar de documentos).\
Esto permite identificar qu√© t√©rminos tienden a aparecer en contextos similares.

**Observaciones:**
> El modelo logra buenas asociaciones en algunos casos, pero tambi√©n introduce bastante ruido y errores tipogr√°ficos.

Colab: [document_similarity_vectorization](https://colab.research.google.com/github/claudiobarril/pln1_17co2024/blob/main/Desafio_1.ipynb)

---

## Desaf√≠o 2: Embeddings Personalizados

Se entrenan embeddings de palabras utilizando como corpus los cuentos de *"Las mil y una noches"*.\
Se prueban dos enfoques de segmentaci√≥n del texto: por **p√°ginas** y por **l√≠neas**.

**Comparaci√≥n de modelos:**
- Ambos enfoques generan listas de t√©rminos similares con peque√±as variaciones.
- El modelo por p√°ginas tiende a producir resultados m√°s **literarios y contextuales**, mientras que el de l√≠neas ofrece t√©rminos m√°s **variados y espec√≠ficos**.

**Conclusiones del test de analog√≠as:**
- El modelo basado en p√°ginas muestra mayor coherencia sem√°ntica en las analog√≠as.
- El modelo por l√≠neas genera algunas respuestas acertadas, pero tambi√©n otras inesperadas.
- Esto evidencia que la **segmentaci√≥n del corpus influye significativamente** en las relaciones sem√°nticas que el modelo captura.

Colab: [custom_embeddings](https://colab.research.google.com/github/claudiobarril/pln1_17co2024/blob/main/Desafio_2.ipynb)

---

## Desaf√≠o 3: Modelo Predictivo de Caracteres

Se construyen modelos RNN para predecir secuencias de caracteres a partir de un corpus b√≠blico.\

**Comparaci√≥n de m√©tricas:**\
![img.png](./images/modelos_desafio_3.png)

**Resumen de resultados:**
- **Modelo 1 (SimpleRNN)**: Mejor perplexity media (entre 4 y 6), demuestra ser competitivo pese a su arquitectura b√°sica.
- **Modelo 2 (GRU + Embedding)**: Peor desempe√±o. El tama√±o reducido del vocabulario (62) no se benefici√≥ de embeddings, y la capacidad de la GRU result√≥ limitada.
- **Modelo 3 (LSTM ligero)**: Rendimiento ligeramente mejor que el modelo GRU, pero inferior a los modelos 1 y 4.
- **Modelo 4 (LSTM con dos capas)**: Mejor resultado en t√©rminos de p√©rdida, indica buen ajuste al entrenamiento.

Colab: [char_prediction_rnn](https://colab.research.google.com/github/claudiobarril/pln1_17co2024/blob/main/Desafio_3.ipynb)

---

## Desaf√≠o 4: Chatbot QA con LSTM

Se implementa un chatbot de preguntas y respuestas basado en redes LSTM.

**Arquitectura utilizada:**\
![img.png](images/arquitectura_desafio_4.png)

**Evaluaci√≥n:**
- Las respuestas generadas no fueron satisfactorias. Se observaron repeticiones y falta de coherencia con las preguntas.
- Se evalu√≥ con las preguntas propuestas por la c√°tedra y otras distintas, sin obtener buenos resultados.

**Pruebas adicionales realizadas (no incluidas en la notebook):**
- Early stopping y model checkpoint instanciados.
- Entrenamiento extendido con mayor longitud de entrada.
- Modificaciones menores al modelo.

**Decisi√≥n final:**
- Se mantuvo solamente la versi√≥n final que representa mejor lo realizado, reduciendo el ruido de intentos fallidos.
- Se considera que hay espacio para nuevas pruebas y mejoras, por lo que quedo abierto a sugerencias.

Colab: [lstm_chatbot_qa](https://colab.research.google.com/github/claudiobarril/pln1_17co2024/blob/main/Desafio_4.ipynb)

---

## Contacto
üìß claudiobarril@gmail.com

---

## ¬°Gracias!
