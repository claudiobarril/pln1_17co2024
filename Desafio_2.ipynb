{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "npl",
      "display_name": "Python (npl)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiobarril/pln1_17co2024/blob/main/Desafio_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "F3CNbPztnmzU"
      },
      "cell_type": "markdown",
      "source": [
        "## Desafío 2: Custom embedddings con Gensim"
      ]
    },
    {
      "metadata": {
        "id": "Okf_AjJxnmzW"
      },
      "cell_type": "markdown",
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizarán los cuentos de \"Las mil y una noches\" para generar los embeddings, es decir, que los vectores tendrán la forma en función de como se hayan utilizado las palabras en dichas historias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pexls2458ThN",
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:06.013104Z",
          "start_time": "2025-04-03T02:45:06.010046Z"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import requests\n",
        "import fitz\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "import fitz\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "fK5j69x7nmzX"
      },
      "cell_type": "markdown",
      "source": [
        "Convertir PDF descargado de https://www.textos.info/anonimo/las-mil-y-una-noches a TXT"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:11.358718Z",
          "start_time": "2025-04-03T02:45:06.082350Z"
        },
        "id": "NboviY6BnmzX"
      },
      "cell_type": "code",
      "source": [
        "def pdf_to_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])  # Extraer texto de cada página\n",
        "    return text\n",
        "\n",
        "# Cargar y guardar el texto\n",
        "pdf_text = pdf_to_text(\"desafio_2/Anonimo - Las Mil y Una Noches.pdf\")\n",
        "with open(\"desafio_2/las-mil-y-una-noches.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(pdf_text)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "IzUoEnQjnmzX"
      },
      "cell_type": "markdown",
      "source": [
        "#### Construcción del corpus\n",
        "\n",
        "Vamos a probar dos estratégias distintas. Crear un documento por cada línea del libro, y un documento por cada página.\n",
        "Sería interesante probar un documento por cuento, pero la separación del libro en cuentos no es trivial, y debería utilizarse una lista de todos los cuentos para dicha tarea. Se abordó esa idea sin éxito en un tiempo prudente, por lo que fue descartada.\n",
        "\n",
        "Como lado positivo, vamos a tener documentos cortos y contexto local, aunque como contra punto, puede que dicho contexto local se pierda en varias situaciones, dado que cortamos indiscriminadamente cuentos por la mitad, ya sea por línea o por página."
      ]
    },
    {
      "metadata": {
        "id": "aXxZ9wn4nmzX"
      },
      "cell_type": "markdown",
      "source": [
        "##### Un documento por página"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:11.432545Z",
          "start_time": "2025-04-03T02:45:11.359635Z"
        },
        "id": "DS5znWS4nmzX",
        "outputId": "af1efd70-9c4e-4583-dc2b-96584736c2c4"
      },
      "cell_type": "code",
      "source": [
        "# Leer el archivo .txt completo\n",
        "with open(\"desafio_2/las-mil-y-una-noches.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Dividir por páginas usando saltos dobles de línea\n",
        "pages = text.split(\"\\n\\n\")\n",
        "\n",
        "# Filtrar líneas que son solo números (números de página)\n",
        "clean_pages = [re.sub(r\"^\\d+$\", \"\", page, flags=re.MULTILINE).strip() for page in pages]\n",
        "\n",
        "# Eliminar entradas vacías después de la limpieza\n",
        "clean_pages = [page for page in clean_pages if page]\n",
        "\n",
        "# Quitar las primeras 6 páginas (introducción)\n",
        "clean_pages = clean_pages[6:]\n",
        "\n",
        "# Crear un DataFrame con cada página limpia como un documento\n",
        "df_by_pages = pd.DataFrame(clean_pages, columns=[\"text\"])\n",
        "\n",
        "# Mostrar algunas páginas procesadas\n",
        "for i, page in enumerate(df_by_pages[\"text\"].head(7)):\n",
        "    print(f\"\\n--- Página {i+1} ---\\n\")\n",
        "    print(page[:500])  # Mostrar los primeros 500 caracteres de cada fragmento\n",
        "\n",
        "print(\"\\nCantidad de documentos:\", df_by_pages.shape[0])"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Página 1 ---\n",
            "\n",
            "Historia del rey Schahriar y su hermano el rey \n",
            "Schahzaman\n",
            "Cuéntase —pero Alah es más sabio, más prudente más poderoso y más \n",
            "benéfico— que en lo que transcurrió en la antigüedad del tiempo y en lo \n",
            "pasado de la edad, hubo un rey entre los reyes de Sassan, en las islas de \n",
            "la India y de la China. Era dueño de ejércitos y señor de auxiliares, de \n",
            "servidores y de un séquito numeroso. Tenía dos hijos, y ambos eran \n",
            "heroicos jinetes, pero el mayor valía más aún que el menor. El mayor reinó \n",
            "en los p\n",
            "\n",
            "--- Página 2 ---\n",
            "\n",
            "hermano?» Desenvainó inmediatamente su alfanje, y acometiendo a \n",
            "ambos, los dejó muertos sobre los tapices del lecho. Volvió a salir sin \n",
            "perder una hora ni un instante, y ordenó la marcha de la comitiva. Y viajó \n",
            "de noche, hasta avistar la ciudad de su hermano.\n",
            "Entonces éste se alegró de su proximidad, salió a su encuentro, y al \n",
            "recibirlo, le deseó la paz. Se regocijó hasta los mayores límites del \n",
            "contento, mandó adornar en honor suyo la ciudad, y se puso a hablarle \n",
            "lleno de efusión. Pero el\n",
            "\n",
            "--- Página 3 ---\n",
            "\n",
            "toda su alma después de haberse alimentado parcamente en los primeros \n",
            "días. Se asombró de ello, y dijo: «Hermano, poco ha te veía amarillo de tez \n",
            "y ahora has recuperado los colores. Cuéntame qué te pasa». El rey le dijo: \n",
            "«Te contaré la causa de mi anterior palidez, pero dispénsame de referirte \n",
            "el motivo de haber recobrado los colores». El rey replicó: «Para \n",
            "entendernos, relata primeramente la causa de tu pérdida de color y tu \n",
            "debilidad». Y se explicó de este modo: «Sabrás hermano, que cuan\n",
            "\n",
            "--- Página 4 ---\n",
            "\n",
            "mar salada. En aquella pradera había un manantial de agua dulce. \n",
            "Bebieron de ella y se sentaron a descansar.\n",
            "Apenas había transcurrido una hora del día, cuando el mar empezó a \n",
            "agitarse. De pronto brotó de él una negra columna de humo, que llegó \n",
            "hasta el cielo y se dirigió después hacia la pradera. Los reyes, asustados, \n",
            "se subieron a la cima del árbol, que era muy alto, y se pusieron a mirar lo \n",
            "que tal cosa pudiera ser. Y he aquí que la columna de humo se convirtió \n",
            "en un efrit de elevada es\n",
            "\n",
            "--- Página 5 ---\n",
            "\n",
            "ojos? Si no venís y me obedecéis, llamo inmediatamente al efrit». \n",
            "Entonces, por miedo al efrit hicieron con ella lo que les había pedido. \n",
            "Cuando los hubo agotado, les dijo: «¡Qué expertos sois los dos!» Sacó del \n",
            "bolsillo un saquito y del saquito un collar compuesto de quinientas setenta \n",
            "sortijas con sellos, y les preguntó: «¿Sabéis lo que es esto?» Ellos \n",
            "contestaron: «No lo sabemos». Entonces les explicó la joven: «Los dueños \n",
            "de estos anillos me han poseído todos junto a los cuernos insens\n",
            "\n",
            "--- Página 6 ---\n",
            "\n",
            "para los asaltos de este cabalgador.\n",
            "En esta situación, el rey mandó al visir que, como de costumbre, le trajese \n",
            "una joven. El visir, por más que buscó, no pudo encontrar ninguna, y \n",
            "regresó muy triste a su casa, con el alma transida de miedo ante el furor \n",
            "del rey. Pero este visir tenía dos hijas de gran hermosura, que poseían \n",
            "todos los encantos, todas las perfecciones y eran de una delicadeza \n",
            "exquisita. La mayor se llamaba Schehrazada , y el nombre de la menor era \n",
            "Doniazada.\n",
            "La mayor, Sche\n",
            "\n",
            "--- Página 7 ---\n",
            "\n",
            "Fábulas del asno, el buey y el labrador\n",
            "«Has de saber, hija mía, que hubo un comerciante dueño de grandes \n",
            "riquezas y de mucho ganado. Estaba casado y con hijos. Alah, el Altísimo, \n",
            "le dio igualmente el conocimiento de los lenguajes de los animales y el \n",
            "canto de los pájaros. Habitaba este comerciante en un país fértil, a orillas \n",
            "de un río. En su morada había un asno y un buey.\n",
            "»Cierto día llegó el buey al lugar ocupado por el asno y vio aquel sitio \n",
            "barrido y regado. En el pesebre había cebada\n",
            "\n",
            "Cantidad de documentos: 3626\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:12.094022Z",
          "start_time": "2025-04-03T02:45:11.433178Z"
        },
        "id": "ve0QQEoEnmzY"
      },
      "cell_type": "code",
      "source": [
        "sentence_tokens_by_pages = [text_to_word_sequence(page) for page in clean_pages]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ],
      "metadata": {
        "id": "Picq7M-8Fa_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model_by_pages = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,# dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=4,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model_by_pages.build_vocab(sentence_tokens_by_pages)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model_by_pages.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model_by_pages.wv.index_to_key))"
      ],
      "metadata": {
        "id": "oiacqmNfFeff",
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:12.310024Z",
          "start_time": "2025-04-03T02:45:12.095356Z"
        },
        "outputId": "1e32c322-c57f-4673-a817-2ba2e2631871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de docs en el corpus: 3626\n",
            "Cantidad de words distintas en el corpus: 12882\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Cjt2BCiSnmzY"
      },
      "cell_type": "markdown",
      "source": [
        "##### Un documento por línea"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:12.386237Z",
          "start_time": "2025-04-03T02:45:12.310647Z"
        },
        "id": "elF_cMjTnmzY",
        "outputId": "fdf8e3da-02dc-4536-a176-b25f2d53b54f"
      },
      "cell_type": "code",
      "source": [
        "# Leer el archivo .txt línea por línea\n",
        "with open(\"desafio_2/las-mil-y-una-noches.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Limpiar cada línea: quitar espacios extra y números de página\n",
        "clean_lines = [re.sub(r\"^\\d+$\", \"\", line.strip()) for line in lines]\n",
        "\n",
        "# Eliminar líneas vacías después de la limpieza\n",
        "clean_lines = [line for line in clean_lines if line]\n",
        "\n",
        "# Quitar las primeras 140 líneas (introducción)\n",
        "clean_lines = clean_lines[126:]\n",
        "\n",
        "# Crear DataFrame con cada línea como un documento\n",
        "df_by_lines = pd.DataFrame(clean_lines, columns=[\"text\"])\n",
        "\n",
        "# Mostrar algunas líneas procesadas\n",
        "for i, line in enumerate(df_by_lines[\"text\"].head(10)):\n",
        "    print(f\"Línea {i}: {line}\")  # Mostrar la línea completa\n",
        "\n",
        "print(\"\\nCantidad de documentos:\", df_by_lines.shape[0])"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Línea 0: Historia del rey Schahriar y su hermano el rey\n",
            "Línea 1: Schahzaman\n",
            "Línea 2: Cuéntase —pero Alah es más sabio, más prudente más poderoso y más\n",
            "Línea 3: benéfico— que en lo que transcurrió en la antigüedad del tiempo y en lo\n",
            "Línea 4: pasado de la edad, hubo un rey entre los reyes de Sassan, en las islas de\n",
            "Línea 5: la India y de la China. Era dueño de ejércitos y señor de auxiliares, de\n",
            "Línea 6: servidores y de un séquito numeroso. Tenía dos hijos, y ambos eran\n",
            "Línea 7: heroicos jinetes, pero el mayor valía más aún que el menor. El mayor reinó\n",
            "Línea 8: en los países, gobernó con justicia entre los hombres y por eso le querían\n",
            "Línea 9: los habitantes del país y del reino. Llamábase el rey Schahriar. Su\n",
            "\n",
            "Cantidad de documentos: 105622\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:13.726387Z",
          "start_time": "2025-04-03T02:45:12.387051Z"
        },
        "id": "IZj4_BIenmzZ",
        "outputId": "cadebb94-4e11-4318-aa27-eec2af5a197c"
      },
      "cell_type": "code",
      "source": [
        "# Tokenizar cada línea en palabras\n",
        "sentence_tokens_by_lines = [text_to_word_sequence(line) for line in clean_lines]\n",
        "\n",
        "# Definir y entrenar el modelo Word2Vec\n",
        "w2v_model_by_lines = Word2Vec(\n",
        "    min_count=5,    # Frecuencia mínima de palabra\n",
        "    window=2,       # Contexto a considerar (palabras antes y después)\n",
        "    vector_size=300,# Dimensión de los embeddings\n",
        "    negative=20,    # Negative sampling\n",
        "    workers=4,      # Número de núcleos para entrenamiento\n",
        "    sg=1            # Skip-gram (1) en lugar de CBOW (0)\n",
        ")\n",
        "\n",
        "# Construir vocabulario\n",
        "w2v_model_by_lines.build_vocab(sentence_tokens_by_lines)\n",
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model_by_lines.corpus_count)\n",
        "\n",
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model_by_lines.wv.index_to_key))"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de docs en el corpus: 105622\n",
            "Cantidad de words distintas en el corpus: 12882\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Entrenar embeddings"
      ],
      "metadata": {
        "id": "xbmNEgJTFnqH"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:13.729432Z",
          "start_time": "2025-04-03T02:45:13.727178Z"
        },
        "id": "Ugfo9iW3nmzZ"
      },
      "cell_type": "code",
      "source": [
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores, por página\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model_by_pages.train(sentence_tokens_by_pages,\n",
        "    total_examples=w2v_model_by_pages.corpus_count,\n",
        "    epochs=50,\n",
        "    compute_loss = True,\n",
        "    callbacks=[callback()]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoZGkDUhFl07",
        "outputId": "1eac5241-4b6c-410a-933f-1d13acaa43cf",
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:28.147684Z",
          "start_time": "2025-04-03T02:45:13.729950Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss after epoch 0: 2336729.5\n",
            "Loss after epoch 1: 1775423.0\n",
            "Loss after epoch 2: 1626203.0\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Entrenamos el modelo generador de vectores, por página\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Utilizamos nuestro callback\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mw2v_model_by_pages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_tokens_by_pages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw2v_model_by_pages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/posgrado/procesamiento_lenguaje_natural/npl/lib/python3.12/site-packages/gensim/models/word2vec.py:1073\u001b[39m, in \u001b[36mWord2Vec.train\u001b[39m\u001b[34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     callback.on_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28mself\u001b[39m._train_epoch_corpusfile(\n\u001b[32m   1079\u001b[39m         corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words,\n\u001b[32m   1080\u001b[39m         callbacks=callbacks, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/posgrado/procesamiento_lenguaje_natural/npl/lib/python3.12/site-packages/gensim/models/word2vec.py:1434\u001b[39m, in \u001b[36mWord2Vec._train_epoch\u001b[39m\u001b[34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[39m\n\u001b[32m   1431\u001b[39m     thread.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[32m   1432\u001b[39m     thread.start()\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m trained_word_count, raw_word_count, job_tally = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dev/posgrado/procesamiento_lenguaje_natural/npl/lib/python3.12/site-packages/gensim/models/word2vec.py:1289\u001b[39m, in \u001b[36mWord2Vec._log_epoch_progress\u001b[39m\u001b[34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[39m\n\u001b[32m   1286\u001b[39m unfinished_worker_count = \u001b[38;5;28mself\u001b[39m.workers\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m     report = \u001b[43mprogress_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[32m   1290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[32m   1291\u001b[39m         unfinished_worker_count -= \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "C0i2cvo4nmzZ"
      },
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores, por línea\n",
        "w2v_model_by_lines.train(sentence_tokens_by_lines,\n",
        "    total_examples=w2v_model_by_lines.corpus_count,\n",
        "    epochs=50,\n",
        "    compute_loss = True,\n",
        "    callbacks=[callback()]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos los modelos\n",
        "with open('models/w2v_model_by_pages.pkl', 'wb') as file:\n",
        "    pickle.dump(w2v_model_by_pages, file)\n",
        "\n",
        "with open('models/w2v_model_by_lines.pkl', 'wb') as file:\n",
        "    pickle.dump(w2v_model_by_lines, file)"
      ],
      "metadata": {
        "id": "LDTBEee68rgC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "3s5btQXpnmzZ"
      },
      "cell_type": "markdown",
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los modelos desde archivo (no es necesario si los entrenamos en esta corrida)\n",
        "with open('models/w2v_model_by_pages.pkl', 'rb') as file:\n",
        "    w2v_model_by_pages = pickle.load(file)\n",
        "\n",
        "with open('models/w2v_model_by_lines.pkl', 'rb') as file:\n",
        "    w2v_model_by_lines = pickle.load(file)"
      ],
      "metadata": {
        "id": "VVaNPcDGW0iJ",
        "ExecuteTime": {
          "end_time": "2025-04-03T02:45:42.600880Z",
          "start_time": "2025-04-03T02:45:42.564483Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_by_pages.wv.most_similar(positive=[\"lámpara\"], topn=10)"
      ],
      "metadata": {
        "id": "HFtl1WL2HWqt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "YZvynxcanmzZ"
      },
      "cell_type": "code",
      "source": [
        "w2v_model_by_lines.wv.most_similar(positive=[\"lámpara\"], topn=10)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "eUh_JAlknmzZ"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def compare_models(word, model_by_pages, model_by_lines, topn=10):\n",
        "    # Obtener palabras más similares en ambos modelos\n",
        "    similar_by_pages = model_by_pages.wv.most_similar(positive=[word], topn=topn)\n",
        "    similar_by_lines = model_by_lines.wv.most_similar(positive=[word], topn=topn)\n",
        "\n",
        "    # Convertir a listas formateadas\n",
        "    words_pages = [f\"{w[0]} ({w[1]:.2f})\" for w in similar_by_pages]\n",
        "    words_lines = [f\"{w[0]} ({w[1]:.2f})\" for w in similar_by_lines]\n",
        "\n",
        "    # Asegurar que ambas listas tengan el mismo tamaño\n",
        "    max_len = max(len(words_pages), len(words_lines))\n",
        "    words_pages += [\"\"] * (max_len - len(words_pages))\n",
        "    words_lines += [\"\"] * (max_len - len(words_lines))\n",
        "\n",
        "    # Crear tabla formateada\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"Comparación para la palabra: {word}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"   Model By Pages   |  Model By Lines \")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for w1, w2 in zip(words_pages, words_lines):\n",
        "        print(f\" {w1.ljust(18)} | {w2}\")\n",
        "\n",
        "    print(\"-\" * 50)  # Línea final separadora\n",
        "\n",
        "# Lista de palabras a comparar\n",
        "words = [\"lámpara\", \"sultán\", \"genio\", \"alfombra\", \"califa\", \"anillo\", \"príncipe\", \"emir\", \"mezquita\", \"palacio\", \"seda\", \"puñal\", \"incienso\", \"destino\"]\n",
        "\n",
        "# Generar comparación para cada palabra\n",
        "for word in words:\n",
        "    compare_models(word, w2v_model_by_pages, w2v_model_by_lines)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "zbyMG26GnmzZ"
      },
      "cell_type": "markdown",
      "source": []
    },
    {
      "metadata": {
        "id": "FKaYs6CwnmzZ"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos observar muchas palabras con asociaciones semánticamente relacionadas. Por ejemplo:\n",
        "* \"lámpara\" se asocia con \"mágica\", \"ánfora\" y \"antorcha\", lo cual encaja con la idea de una lámpara mágica en contextos como \"Las Mil y Una Noches\".\n",
        "* \"genio\" tiene asociaciones con términos como \"gigantesco\" y \"sucio\", que podrían reflejar características típicas en descripciones de genios en la literatura.\n",
        "* \"anillo\" tiene fuertes asociaciones con \"talismánico\", \"engarce\" y \"brazalete\", lo que sugiere que se vincula a conceptos de joyería y magia.\n",
        "\n",
        "Ambos modelos parecen generar listas con relaciones similares, pero con algunas variaciones en las puntuaciones y las palabras asociadas. En algunos casos, el modelo por páginas tiende a producir términos más literarios o contextuales, mientras que el modelo por líneas parece generar términos más variados y específicos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensayar con una palabra que no está en el vocabulario:\n",
        "w2v_model_by_pages.wv.most_similar(negative=[\"diedaa\"])"
      ],
      "metadata": {
        "id": "mUNf3R6T9OSM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# el método `get_vector` permite obtener los vectores:\n",
        "vector_palacio = w2v_model_by_pages.wv.get_vector(\"palacio\")\n",
        "print(vector_palacio)"
      ],
      "metadata": {
        "id": "K6zxz8-n92Bf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# el método `most_similar` también permite comparar a partir de vectores\n",
        "w2v_model_by_pages.wv.most_similar(vector_palacio)"
      ],
      "metadata": {
        "id": "ipjOzoQa9_24"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 - Visualizar agrupación de vectores\n"
      ],
      "metadata": {
        "id": "kpMfe4Ps-GzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ],
      "metadata": {
        "id": "ERU9bEO--HLt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 2D\n",
        "vecs, labels = reduce_dimensions(w2v_model_by_pages)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS, 0], y=vecs[:MAX_WORDS, 1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "id": "wMceS7RR-JEN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 3D\n",
        "vecs, labels = reduce_dimensions(w2v_model_by_pages, 3)\n",
        "\n",
        "fig = px.scatter_3d(x=vecs[:MAX_WORDS, 0], y=vecs[:MAX_WORDS, 1], z=vecs[:MAX_WORDS, 2],text=labels[:MAX_WORDS])\n",
        "fig.update_traces(marker_size = 2)\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "id": "EVe6isc4-Lh8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "vectors = np.asarray(w2v_model_by_pages.wv.vectors)\n",
        "labels = list(w2v_model_by_pages.wv.index_to_key)\n",
        "\n",
        "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "with open(\"labels.tsv\", \"w\") as fp:\n",
        "    for item in labels:\n",
        "        fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "L6WxUwJq-NGC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 - Tests de analogías"
      ],
      "metadata": {
        "id": "J0VO0GcS-UKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de analogía\n",
        "def analogy(model, word_a, word_b, word_c, topn=10):\n",
        "    \"\"\"\n",
        "    Encuentra la palabra D que complete la analogía: A es a B como C es a ?\n",
        "\n",
        "    Parámetros:\n",
        "    - model: modelo Word2Vec entrenado\n",
        "    - word_a, word_b, word_c: palabras en la analogía\n",
        "    - topn: cantidad de palabras más similares a mostrar\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de palabras similares con sus puntuaciones\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = model.wv.most_similar(positive=[word_b, word_c], negative=[word_a], topn=topn)\n",
        "        return result\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}. Alguna palabra no está en el vocabulario.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "R76bhd5F-YAO",
        "ExecuteTime": {
          "end_time": "2025-04-03T02:48:25.211589Z",
          "start_time": "2025-04-03T02:48:25.204782Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-03T03:05:24.176866Z",
          "start_time": "2025-04-03T03:05:24.139452Z"
        },
        "id": "oR9rCGVMnmza",
        "outputId": "bb7e4145-82ac-4104-89d4-d39aa6c7e8ee"
      },
      "cell_type": "code",
      "source": [
        "def analogy_compare_models(model_by_pages, model_by_lines, word_a, word_b, word_c, topn=10):\n",
        "    \"\"\"\n",
        "    Compara los resultados de la analogía en dos modelos de Word2Vec.\n",
        "\n",
        "    Parámetros:\n",
        "    - model_by_pages: modelo Word2Vec entrenado por páginas\n",
        "    - model_by_lines: modelo Word2Vec entrenado por líneas\n",
        "    - word_a, word_b, word_c: palabras en la analogía (A es a B como C es a ?)\n",
        "    - topn: cantidad de palabras más similares a mostrar\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener resultados de analogía para ambos modelos\n",
        "    similar_by_pages = analogy(model_by_pages, word_a, word_b, word_c, topn)\n",
        "    similar_by_lines = analogy(model_by_lines, word_a, word_b, word_c, topn)\n",
        "\n",
        "    # Manejar errores si alguna palabra no está en el vocabulario\n",
        "    if similar_by_pages is None or similar_by_lines is None:\n",
        "        return\n",
        "\n",
        "    # Convertir a listas formateadas\n",
        "    words_pages = [f\"{w[0]} ({w[1]:.2f})\" for w in similar_by_pages]\n",
        "    words_lines = [f\"{w[0]} ({w[1]:.2f})\" for w in similar_by_lines]\n",
        "\n",
        "    # Asegurar que ambas listas tengan el mismo tamaño\n",
        "    max_len = max(len(words_pages), len(words_lines))\n",
        "    words_pages += [\"\"] * (max_len - len(words_pages))\n",
        "    words_lines += [\"\"] * (max_len - len(words_lines))\n",
        "\n",
        "    # Crear tabla formateada\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Comparación para la analogía: '{word_a}' es a '{word_b}' lo que '{word_c}' es a:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"   Model By Pages   |  Model By Lines \")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for w1, w2 in zip(words_pages, words_lines):\n",
        "        print(f\" {w1.ljust(20)} | {w2}\")\n",
        "\n",
        "    print(\"-\" * 60)  # Línea final separadora\n",
        "\n",
        "# Lista de analogías a comparar\n",
        "analogies = [\n",
        "    (\"princesa\", \"príncipe\", \"reina\"),\n",
        "    (\"jeque\", \"tribu\", \"califa\"),\n",
        "    (\"anillo\", \"engarce\", \"palacio\"),\n",
        "    (\"sultán\", \"palacio\", \"mercader\"),\n",
        "]\n",
        "\n",
        "# Generar comparación para cada analogía\n",
        "for word_a, word_b, word_c in analogies:\n",
        "    analogy_compare_models(w2v_model_by_pages, w2v_model_by_lines, word_a, word_b, word_c)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Comparación para la analogía: 'princesa' es a 'príncipe' lo que 'reina' es a:\n",
            "============================================================\n",
            "   Model By Pages   |  Model By Lines \n",
            "------------------------------------------------------------\n",
            " hossein (0.32)       | púsose (0.30)\n",
            " rey (0.29)           | hossein (0.30)\n",
            " cargador (0.27)      | héroe (0.29)\n",
            " escuchamos (0.26)    | mostrándole (0.27)\n",
            " faruz (0.26)         | rey (0.26)\n",
            " derbas (0.26)        | nazarenos (0.26)\n",
            " rumzán (0.26)        | yamlika (0.26)\n",
            " pastelero (0.26)     | ¡durante (0.26)\n",
            " porteros (0.26)      | estrictamente (0.26)\n",
            " oriunda (0.26)       | cansaba (0.26)\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Comparación para la analogía: 'jeque' es a 'tribu' lo que 'califa' es a:\n",
            "============================================================\n",
            "   Model By Pages   |  Model By Lines \n",
            "------------------------------------------------------------\n",
            " califal (0.28)       | castigarme (0.28)\n",
            " mí (0.27)            | continua (0.27)\n",
            " billah (0.26)        | avisarme (0.27)\n",
            " marchaban (0.25)     | devolverme (0.27)\n",
            " pida (0.25)          | califal (0.27)\n",
            " caballería (0.25)    | emisarios (0.26)\n",
            " escritas (0.25)      | cantaré (0.26)\n",
            " insomnios (0.25)     | invocó (0.25)\n",
            " afrenta (0.24)       | individuos (0.25)\n",
            " mataría (0.24)       | ansaritas (0.25)\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Comparación para la analogía: 'anillo' es a 'engarce' lo que 'palacio' es a:\n",
            "============================================================\n",
            "   Model By Pages   |  Model By Lines \n",
            "------------------------------------------------------------\n",
            " penetramos (0.39)    | pórtico (0.40)\n",
            " gradas (0.38)        | penetramos (0.39)\n",
            " celda (0.38)         | celda (0.39)\n",
            " espacioso (0.38)     | dejándolo (0.38)\n",
            " ladrillos (0.37)     | gradas (0.37)\n",
            " fuelle (0.37)        | harem (0.37)\n",
            " pórtico (0.37)       | trigésimo (0.37)\n",
            " astrolabio (0.36)    | astrolabio (0.37)\n",
            " doradas (0.36)       | caminaron (0.36)\n",
            " silbido (0.36)       | vestíbulo (0.35)\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Comparación para la analogía: 'sultán' es a 'palacio' lo que 'mercader' es a:\n",
            "============================================================\n",
            "   Model By Pages   |  Model By Lines \n",
            "------------------------------------------------------------\n",
            " tienda (0.30)        | caballo (0.26)\n",
            " enjaezada (0.29)     | pasillo (0.25)\n",
            " estrado (0.27)       | bordo (0.24)\n",
            " casa (0.26)          | harem (0.24)\n",
            " confitero (0.26)     | acercándose (0.24)\n",
            " maghreb (0.26)       | khan (0.24)\n",
            " desván (0.26)        | local (0.24)\n",
            " papeletas (0.26)     | bolsillo (0.24)\n",
            " desanduvo (0.26)     | criada (0.24)\n",
            " serur (0.25)         | schaibar (0.24)\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "WUT13eB5nmza"
      },
      "cell_type": "markdown",
      "source": [
        "#### Análisis de Analogías\n",
        "\n",
        "1. \"princesa\" es a \"príncipe\" lo que \"reina\" es a:\n",
        "\n",
        "* El modelo basado en páginas tiene \"rey\" como una de las respuestas más cercanas, lo que es lógico dada la relación monárquica.\n",
        "* El modelo basado en líneas sugiere \"héroe\" y \"hossein\", posiblemente reflejando asociaciones narrativas dentro del texto.\n",
        "* Otras respuestas como \"pastelero\" o \"porteros\" en el modelo por páginas parecen menos relacionadas semánticamente con la analogía planteada.\n",
        "\n",
        "2. \"jeque\" es a \"tribu\" lo que \"califa\" es a:\n",
        "\n",
        "* En el modelo basado en páginas, \"califal\" aparece como la mejor opción, lo que tiene sentido, dado que \"califa\" está relacionado con \"califato\".\n",
        "* El modelo basado en líneas genera respuestas menos relacionadas, como \"castigarme\" o \"avisarme\".\n",
        "* La presencia de \"emisarios\" en el modelo por líneas podría estar relacionada con el contexto histórico de los califas y su diplomacia.\n",
        "\n",
        "3. \"anillo\" es a \"engarce\" lo que \"palacio\" es a:\n",
        "\n",
        "* El modelo basado en líneas sugiere \"pórtico\", \"vestíbulo\" y \"harem\", palabras asociadas a palacios.\n",
        "* El modelo basado en páginas genera respuestas como \"penetramos\", \"celda\" y \"gradas\", lo que también está relacionado con estructuras arquitectónicas.\n",
        "* La presencia de \"astrolabio\" en ambas listas sugiere que en la narrativa el término está asociado a palacios.\n",
        "\n",
        "4. \"sultán\" es a \"palacio\" lo que \"mercader es a:\n",
        "\n",
        "* \"tienda\" aparece como la mejor respuesta en el modelo basado en páginas, lo que es una elección semánticamente coherente.\n",
        "* En el modelo basado en líneas, aparecen palabras menos esperadas como \"caballo\" y \"pasillo\".\n",
        "* \"Khan\" en el modelo basado en líneas podría referirse a posadas orientales, lo que tiene cierto grado de relación con mercaderes.\n",
        "\n",
        "#### Conclusión\n",
        "\n",
        "Los resultados muestran que el modelo basado en páginas tiende a producir respuestas más alineadas con el significado semántico esperado en cada analogía. En cambio, el modelo basado en líneas genera algunas respuestas coherentes, pero también incorpora términos menos esperados, lo que podría deberse a asociaciones específicas del contexto narrativo en el que aparecen las palabras. Esto sugiere que la segmentación del texto influye significativamente en las asociaciones semánticas que los modelos pueden capturar."
      ]
    },
    {
      "metadata": {
        "id": "J2yqpHawnmza"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": []
    }
  ]
}