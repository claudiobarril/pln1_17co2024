{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3yeJGnCYxuF"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Modelo de lenguaje con tokenización por caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv5PEwGzZA9-"
   },
   "source": [
    "### Consigna\n",
    "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
    "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
    "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
    "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
    "\n",
    "\n",
    "### Sugerencias\n",
    "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
    "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
    "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y-QdFbHZYj7C"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU, Input, TimeDistributed, CategoryEncoding, SimpleRNN\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para descargas desde textos.info\n",
    "import urllib.request\n",
    "\n",
    "# Para leer y parsear el texto en HTML\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTvXlEKQZdqx"
   },
   "source": [
    "### Datos\n",
    "Utilizaremos como dataset la biblia. Utilizaremos sólo un 5% (ignorando previamente el primer 5%, para saltar el Génesis que quizas no es una parte tan representativa al resto del texto).\n",
    "\n",
    "Se intentó inicialmente procesar un 10%, para tener una longitud de texto similar a la provista el en dataset de ejemplo de la materia (La vuelta al mundo en 80 días), pero el tiempo de procesamiento necesario para las redes neuronales con arquitectura GRU y LSTM excedían el tiempo brindado por Colab, por lo que se procedió con sólo un 5% del texto.\n",
    "\n",
    "Procederemos a quitar saltos de línea y el caracter de espacio no separable, por espacios simples, para simplificar el entrenamiento y predicción de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6v_ickFwBJTy"
   },
   "outputs": [],
   "source": [
    "raw_html = urllib.request.urlopen('https://www.textos.info/varios/biblia/ebook')\n",
    "raw_html = raw_html.read()\n",
    "\n",
    "# parsear artículo, 'lxml' es el parser a utilizar\n",
    "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
    "\n",
    "# encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
    "# y tenerlos disponible como lista\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''\n",
    "\n",
    "for para in article_paragraphs:\n",
    "    article_text += para.text + ' '\n",
    "\n",
    "# pasar todo el texto a minúscula\n",
    "article_text = article_text.lower()\n",
    "\n",
    "# limpiar saltos de línea y otros caracteres extraños\n",
    "article_text = article_text.replace('\\r', ' ').replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "article_text = ' '.join(article_text.split())  # Esto elimina espacios dobles y los deja como uno solo\n",
    "\n",
    "\n",
    "# saltar el 5% inicial\n",
    "skip_portion = 0.05\n",
    "total_len = len(article_text)\n",
    "start = int(total_len * skip_portion)\n",
    "\n",
    "# extraer solo el 5% después del salto\n",
    "portion = 0.05\n",
    "end = start + int(total_len * portion)\n",
    "\n",
    "article_text = article_text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "WBE0sSYuB-E6",
    "outputId": "6795d042-9256-4c06-fbd0-05e1c491fbb5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'ni siquiera un perro ladrará ni contra hombre ni contra bestia; para que sepáis cómo yahveh hace distinción entre egipto e israel. [8] entonces vendrán a mí todos estos siervos tuyos y se postrarán delante de mí, diciendo: sal, tú y todo el pueblo que te sigue. y entonces, saldré.» y, ardiendo en cólera, salió de la presencia de faraón. [9] y dijo yahveh a moisés: «no os escuchará faraón, para que así pueda yo multiplicar mis prodigios en la tierra de egipto.» [10] moisés y aarón obraron todos estos prodigios ante faraón; pero yahveh endureció el corazón de faraón, que no dejó salir de su país a los israelitas. [1] dijo yahveh a moisés y aarón en el país de egipto: [2] «este mes será para vosotros el comienzo de los meses; será el primero de los meses del año. [3] hablad a toda la comunidad de israel y decid: el día diez de este mes tomará cada uno para sí una res de ganado menor por familia, una res de ganado menor por casa. [4] y si la familia fuese demasiado reducida para una res de'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# revisamos el comienzo de la porción extraída, vemos que se trata ya del libro Éxodo\n",
    "article_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cP1JdiOIKQWi"
   },
   "source": [
    "### Elegir el tamaño del contexto\n",
    "\n",
    "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
    "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
    "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wumBNwdjJM3j"
   },
   "outputs": [],
   "source": [
    "# seleccionamos el tamaño de contexto\n",
    "max_context_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ordenamos el vocabulario para poder reproducir la tokenización para el caso en que levantemos un modelo previamente entrenado desde un archivo."
   ],
   "metadata": {
    "id": "aFtNTBJFvZPu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "573Cg5n7VhWw"
   },
   "outputs": [],
   "source": [
    "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
    "chars_vocab = sorted(list(set(article_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwTK6xgLJd8q",
    "outputId": "0f537dd6-67e5-4479-b59e-88b0c6d85379"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# la longitud de vocabulario de caracteres es:\n",
    "len(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_oMNMUT02nk",
    "outputId": "fafb29ef-8d8c-4e00-b47f-2c541be8daf6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '—']\n"
     ]
    }
   ],
   "source": [
    "print(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2W0AeQjXV1Ou"
   },
   "outputs": [],
   "source": [
    "# Construimos los diccionarios que asignan índices a caracteres y viceversa.\n",
    "# El diccionario `char2idx` servirá como tokenizador.\n",
    "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
    "idx2char = {v: k for k,v in char2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oIUjVU0LB0r"
   },
   "source": [
    "###  Tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h07G3srdJppo"
   },
   "outputs": [],
   "source": [
    "# tokenizamos el texto completo\n",
    "tokenized_text = [char2idx[ch] for ch in article_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "PwGVSKOiJ5bj",
    "outputId": "c6b07ec9-50d3-4d93-8172-f395b58f3fa8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[38,\n",
       " 33,\n",
       " 0,\n",
       " 43,\n",
       " 33,\n",
       " 41,\n",
       " 45,\n",
       " 33,\n",
       " 29,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 45,\n",
       " 38,\n",
       " 0,\n",
       " 40,\n",
       " 29,\n",
       " 42,\n",
       " 42,\n",
       " 39,\n",
       " 0,\n",
       " 36,\n",
       " 25,\n",
       " 28,\n",
       " 42,\n",
       " 25,\n",
       " 42,\n",
       " 54,\n",
       " 0,\n",
       " 38,\n",
       " 33,\n",
       " 0,\n",
       " 27,\n",
       " 39,\n",
       " 38,\n",
       " 44,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 32,\n",
       " 39,\n",
       " 37,\n",
       " 26,\n",
       " 42,\n",
       " 29,\n",
       " 0,\n",
       " 38,\n",
       " 33,\n",
       " 0,\n",
       " 27,\n",
       " 39,\n",
       " 38,\n",
       " 44,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 26,\n",
       " 29,\n",
       " 43,\n",
       " 44,\n",
       " 33,\n",
       " 25,\n",
       " 20,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 29,\n",
       " 0,\n",
       " 43,\n",
       " 29,\n",
       " 40,\n",
       " 54,\n",
       " 33,\n",
       " 43,\n",
       " 0,\n",
       " 27,\n",
       " 58,\n",
       " 37,\n",
       " 39,\n",
       " 0,\n",
       " 48,\n",
       " 25,\n",
       " 32,\n",
       " 46,\n",
       " 29,\n",
       " 32,\n",
       " 0,\n",
       " 32,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 33,\n",
       " 43,\n",
       " 44,\n",
       " 33,\n",
       " 38,\n",
       " 27,\n",
       " 33,\n",
       " 58,\n",
       " 38,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 44,\n",
       " 42,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 31,\n",
       " 33,\n",
       " 40,\n",
       " 44,\n",
       " 39,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 33,\n",
       " 43,\n",
       " 42,\n",
       " 25,\n",
       " 29,\n",
       " 36,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 17,\n",
       " 24,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 44,\n",
       " 39,\n",
       " 38,\n",
       " 27,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 46,\n",
       " 29,\n",
       " 38,\n",
       " 28,\n",
       " 42,\n",
       " 54,\n",
       " 38,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 37,\n",
       " 56,\n",
       " 0,\n",
       " 44,\n",
       " 39,\n",
       " 28,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 29,\n",
       " 43,\n",
       " 44,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 43,\n",
       " 33,\n",
       " 29,\n",
       " 42,\n",
       " 46,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 44,\n",
       " 45,\n",
       " 48,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 43,\n",
       " 29,\n",
       " 0,\n",
       " 40,\n",
       " 39,\n",
       " 43,\n",
       " 44,\n",
       " 42,\n",
       " 25,\n",
       " 42,\n",
       " 54,\n",
       " 38,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 36,\n",
       " 25,\n",
       " 38,\n",
       " 44,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 37,\n",
       " 56,\n",
       " 6,\n",
       " 0,\n",
       " 28,\n",
       " 33,\n",
       " 27,\n",
       " 33,\n",
       " 29,\n",
       " 38,\n",
       " 28,\n",
       " 39,\n",
       " 19,\n",
       " 0,\n",
       " 43,\n",
       " 25,\n",
       " 36,\n",
       " 6,\n",
       " 0,\n",
       " 44,\n",
       " 59,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 44,\n",
       " 39,\n",
       " 28,\n",
       " 39,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 40,\n",
       " 45,\n",
       " 29,\n",
       " 26,\n",
       " 36,\n",
       " 39,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 29,\n",
       " 0,\n",
       " 44,\n",
       " 29,\n",
       " 0,\n",
       " 43,\n",
       " 33,\n",
       " 31,\n",
       " 45,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 44,\n",
       " 39,\n",
       " 38,\n",
       " 27,\n",
       " 29,\n",
       " 43,\n",
       " 6,\n",
       " 0,\n",
       " 43,\n",
       " 25,\n",
       " 36,\n",
       " 28,\n",
       " 42,\n",
       " 55,\n",
       " 8,\n",
       " 52,\n",
       " 0,\n",
       " 48,\n",
       " 6,\n",
       " 0,\n",
       " 25,\n",
       " 42,\n",
       " 28,\n",
       " 33,\n",
       " 29,\n",
       " 38,\n",
       " 28,\n",
       " 39,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 0,\n",
       " 27,\n",
       " 58,\n",
       " 36,\n",
       " 29,\n",
       " 42,\n",
       " 25,\n",
       " 6,\n",
       " 0,\n",
       " 43,\n",
       " 25,\n",
       " 36,\n",
       " 33,\n",
       " 58,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 25,\n",
       " 0,\n",
       " 40,\n",
       " 42,\n",
       " 29,\n",
       " 43,\n",
       " 29,\n",
       " 38,\n",
       " 27,\n",
       " 33,\n",
       " 25,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 58,\n",
       " 38,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 18,\n",
       " 24,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 28,\n",
       " 33,\n",
       " 34,\n",
       " 39,\n",
       " 0,\n",
       " 48,\n",
       " 25,\n",
       " 32,\n",
       " 46,\n",
       " 29,\n",
       " 32,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 37,\n",
       " 39,\n",
       " 33,\n",
       " 43,\n",
       " 55,\n",
       " 43,\n",
       " 19,\n",
       " 0,\n",
       " 51,\n",
       " 38,\n",
       " 39,\n",
       " 0,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 29,\n",
       " 43,\n",
       " 27,\n",
       " 45,\n",
       " 27,\n",
       " 32,\n",
       " 25,\n",
       " 42,\n",
       " 54,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 58,\n",
       " 38,\n",
       " 6,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 29,\n",
       " 0,\n",
       " 25,\n",
       " 43,\n",
       " 56,\n",
       " 0,\n",
       " 40,\n",
       " 45,\n",
       " 29,\n",
       " 28,\n",
       " 25,\n",
       " 0,\n",
       " 48,\n",
       " 39,\n",
       " 0,\n",
       " 37,\n",
       " 45,\n",
       " 36,\n",
       " 44,\n",
       " 33,\n",
       " 40,\n",
       " 36,\n",
       " 33,\n",
       " 27,\n",
       " 25,\n",
       " 42,\n",
       " 0,\n",
       " 37,\n",
       " 33,\n",
       " 43,\n",
       " 0,\n",
       " 40,\n",
       " 42,\n",
       " 39,\n",
       " 28,\n",
       " 33,\n",
       " 31,\n",
       " 33,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 0,\n",
       " 36,\n",
       " 25,\n",
       " 0,\n",
       " 44,\n",
       " 33,\n",
       " 29,\n",
       " 42,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 31,\n",
       " 33,\n",
       " 40,\n",
       " 44,\n",
       " 39,\n",
       " 8,\n",
       " 52,\n",
       " 0,\n",
       " 23,\n",
       " 10,\n",
       " 9,\n",
       " 24,\n",
       " 0,\n",
       " 37,\n",
       " 39,\n",
       " 33,\n",
       " 43,\n",
       " 55,\n",
       " 43,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 25,\n",
       " 25,\n",
       " 42,\n",
       " 58,\n",
       " 38,\n",
       " 0,\n",
       " 39,\n",
       " 26,\n",
       " 42,\n",
       " 25,\n",
       " 42,\n",
       " 39,\n",
       " 38,\n",
       " 0,\n",
       " 44,\n",
       " 39,\n",
       " 28,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 29,\n",
       " 43,\n",
       " 44,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 40,\n",
       " 42,\n",
       " 39,\n",
       " 28,\n",
       " 33,\n",
       " 31,\n",
       " 33,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 25,\n",
       " 38,\n",
       " 44,\n",
       " 29,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 58,\n",
       " 38,\n",
       " 20,\n",
       " 0,\n",
       " 40,\n",
       " 29,\n",
       " 42,\n",
       " 39,\n",
       " 0,\n",
       " 48,\n",
       " 25,\n",
       " 32,\n",
       " 46,\n",
       " 29,\n",
       " 32,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 28,\n",
       " 45,\n",
       " 42,\n",
       " 29,\n",
       " 27,\n",
       " 33,\n",
       " 58,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 27,\n",
       " 39,\n",
       " 42,\n",
       " 25,\n",
       " 49,\n",
       " 58,\n",
       " 38,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 58,\n",
       " 38,\n",
       " 6,\n",
       " 0,\n",
       " 41,\n",
       " 45,\n",
       " 29,\n",
       " 0,\n",
       " 38,\n",
       " 39,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 34,\n",
       " 58,\n",
       " 0,\n",
       " 43,\n",
       " 25,\n",
       " 36,\n",
       " 33,\n",
       " 42,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 43,\n",
       " 45,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 56,\n",
       " 43,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 36,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 33,\n",
       " 43,\n",
       " 42,\n",
       " 25,\n",
       " 29,\n",
       " 36,\n",
       " 33,\n",
       " 44,\n",
       " 25,\n",
       " 43,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 10,\n",
       " 24,\n",
       " 0,\n",
       " 28,\n",
       " 33,\n",
       " 34,\n",
       " 39,\n",
       " 0,\n",
       " 48,\n",
       " 25,\n",
       " 32,\n",
       " 46,\n",
       " 29,\n",
       " 32,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 37,\n",
       " 39,\n",
       " 33,\n",
       " 43,\n",
       " 55,\n",
       " 43,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 25,\n",
       " 25,\n",
       " 42,\n",
       " 58,\n",
       " 38,\n",
       " 0,\n",
       " 29,\n",
       " 38,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 56,\n",
       " 43,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 31,\n",
       " 33,\n",
       " 40,\n",
       " 44,\n",
       " 39,\n",
       " 19,\n",
       " 0,\n",
       " 23,\n",
       " 11,\n",
       " 24,\n",
       " 0,\n",
       " 51,\n",
       " 29,\n",
       " 43,\n",
       " 44,\n",
       " 29,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 43,\n",
       " 29,\n",
       " 42,\n",
       " 54,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 46,\n",
       " 39,\n",
       " 43,\n",
       " 39,\n",
       " 44,\n",
       " 42,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 27,\n",
       " 39,\n",
       " 37,\n",
       " 33,\n",
       " 29,\n",
       " 38,\n",
       " 49,\n",
       " 39,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 43,\n",
       " 29,\n",
       " 43,\n",
       " 20,\n",
       " 0,\n",
       " 43,\n",
       " 29,\n",
       " 42,\n",
       " 54,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 40,\n",
       " 42,\n",
       " 33,\n",
       " 37,\n",
       " 29,\n",
       " 42,\n",
       " 39,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 39,\n",
       " 43,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 43,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 25,\n",
       " 57,\n",
       " 39,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 12,\n",
       " 24,\n",
       " 0,\n",
       " 32,\n",
       " 25,\n",
       " 26,\n",
       " 36,\n",
       " 25,\n",
       " 28,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 44,\n",
       " 39,\n",
       " 28,\n",
       " 25,\n",
       " 0,\n",
       " 36,\n",
       " 25,\n",
       " 0,\n",
       " 27,\n",
       " 39,\n",
       " 37,\n",
       " 45,\n",
       " 38,\n",
       " 33,\n",
       " 28,\n",
       " 25,\n",
       " 28,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 33,\n",
       " 43,\n",
       " 42,\n",
       " 25,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 27,\n",
       " 33,\n",
       " 28,\n",
       " 19,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 56,\n",
       " 25,\n",
       " 0,\n",
       " 28,\n",
       " 33,\n",
       " 29,\n",
       " 49,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 43,\n",
       " 44,\n",
       " 29,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 44,\n",
       " 39,\n",
       " 37,\n",
       " 25,\n",
       " 42,\n",
       " 54,\n",
       " 0,\n",
       " 27,\n",
       " 25,\n",
       " 28,\n",
       " 25,\n",
       " 0,\n",
       " 45,\n",
       " 38,\n",
       " 39,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 43,\n",
       " 56,\n",
       " 0,\n",
       " 45,\n",
       " 38,\n",
       " 25,\n",
       " 0,\n",
       " 42,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 31,\n",
       " 25,\n",
       " 38,\n",
       " 25,\n",
       " 28,\n",
       " 39,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 38,\n",
       " 39,\n",
       " 42,\n",
       " 0,\n",
       " 40,\n",
       " 39,\n",
       " 42,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 37,\n",
       " 33,\n",
       " 36,\n",
       " 33,\n",
       " 25,\n",
       " 6,\n",
       " 0,\n",
       " 45,\n",
       " 38,\n",
       " 25,\n",
       " 0,\n",
       " 42,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 31,\n",
       " 25,\n",
       " 38,\n",
       " 25,\n",
       " 28,\n",
       " 39,\n",
       " 0,\n",
       " 37,\n",
       " 29,\n",
       " 38,\n",
       " 39,\n",
       " 42,\n",
       " 0,\n",
       " 40,\n",
       " 39,\n",
       " 42,\n",
       " 0,\n",
       " 27,\n",
       " 25,\n",
       " 43,\n",
       " 25,\n",
       " 8,\n",
       " 0,\n",
       " 23,\n",
       " 13,\n",
       " 24,\n",
       " 0,\n",
       " 48,\n",
       " 0,\n",
       " 43,\n",
       " 33,\n",
       " 0,\n",
       " 36,\n",
       " 25,\n",
       " 0,\n",
       " 30,\n",
       " 25,\n",
       " 37,\n",
       " 33,\n",
       " 36,\n",
       " 33,\n",
       " 25,\n",
       " 0,\n",
       " 30,\n",
       " 45,\n",
       " 29,\n",
       " 43,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 37,\n",
       " 25,\n",
       " 43,\n",
       " 33,\n",
       " 25,\n",
       " 28,\n",
       " 39,\n",
       " 0,\n",
       " 42,\n",
       " 29,\n",
       " 28,\n",
       " 45,\n",
       " 27,\n",
       " 33,\n",
       " 28,\n",
       " 25,\n",
       " 0,\n",
       " 40,\n",
       " 25,\n",
       " 42,\n",
       " 25,\n",
       " 0,\n",
       " 45,\n",
       " 38,\n",
       " 25,\n",
       " 0,\n",
       " 42,\n",
       " 29,\n",
       " 43,\n",
       " 0,\n",
       " 28,\n",
       " 29]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tokenized_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfpYcaypKcI9"
   },
   "source": [
    "### Organizando y estructurando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WSSmg9jtKP0T"
   },
   "outputs": [],
   "source": [
    "# separamos el dataset entre entrenamiento y validación.\n",
    "# `p_val` será la proporción del corpus que se reservará para validación\n",
    "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
    "p_val = 0.1\n",
    "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b7dCpGrdKll0"
   },
   "outputs": [],
   "source": [
    "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
    "train_text = tokenized_text[:-num_val*max_context_size]\n",
    "val_text = tokenized_text[-num_val*max_context_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NmxQdxl8LRCg"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_gyFT9koLqDm"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oVNqmmLRodT0"
   },
   "outputs": [],
   "source": [
    "X = np.array(tokenized_sentences_train[:-1])\n",
    "y = np.array(tokenized_sentences_train[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vken7O4ETsAJ"
   },
   "source": [
    "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
    "\n",
    "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
    "\n",
    "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
    "\n",
    "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
    "\n",
    "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3iPTx-UJl6r"
   },
   "source": [
    "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFAyA4zCWE-5",
    "outputId": "ffba286a-3f75-4d5a-f248-389a87911dc7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(198971, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qcKRl70HFTzG",
    "outputId": "e09554a0-6cfb-4445-dc4a-fe82908d2948"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([38, 33,  0, 43, 33, 41, 45, 33, 29, 42])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "X[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVpLCKSZFXZO",
    "outputId": "a9a01b35-1580-430d-b802-39edc9c49e63"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([33,  0, 43, 33, 41, 45, 33, 29, 42, 25])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "y[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wOFCR-KqbW1N"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(chars_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnnjdAQ5UAEJ"
   },
   "source": [
    "# Definiendo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgz7VKwTUbj6"
   },
   "source": [
    "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmJWNyxQwfCE"
   },
   "source": [
    "\n",
    "### Definir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWK3z85sQfUe"
   },
   "source": [
    "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
    "\n",
    "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "S4tSxcFi5vVD"
   },
   "outputs": [],
   "source": [
    "class PplCallback(keras.callbacks.Callback):\n",
    "\n",
    "    \"\"\"\n",
    "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
    "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
    "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
    "    Además, implementa la finalización del entrenamiento (Early Stopping)\n",
    "    si la perplejidad no mejora después de `patience` epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, val_data, history_ppl, model_name, patience=5):\n",
    "      self.history_ppl = history_ppl\n",
    "      self.model_name = model_name\n",
    "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
    "      # mediremos la perplejidad\n",
    "      self.val_data = val_data\n",
    "\n",
    "      self.target = []\n",
    "      self.padded = []\n",
    "\n",
    "      count = 0\n",
    "      self.info = []\n",
    "      self.min_score = np.inf\n",
    "      self.patience_counter = 0\n",
    "      self.patience = patience\n",
    "\n",
    "      # nos movemos en todas las secuencias de los datos de validación\n",
    "      for seq in self.val_data:\n",
    "\n",
    "        len_seq = len(seq)\n",
    "        # armamos todas las subsecuencias\n",
    "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
    "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
    "\n",
    "        if len(subseq)!=0:\n",
    "\n",
    "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
    "\n",
    "          self.info.append((count,count+len_seq))\n",
    "          count += len_seq\n",
    "\n",
    "      self.padded = np.vstack(self.padded)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
    "        scores = []\n",
    "\n",
    "        predictions = self.model.predict(self.padded,verbose=0)\n",
    "\n",
    "        # para cada secuencia de validación\n",
    "        for start,end in self.info:\n",
    "\n",
    "          # en `probs` iremos guardando las probabilidades de los términos target\n",
    "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
    "\n",
    "          # calculamos la perplejidad por medio de logaritmos\n",
    "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
    "\n",
    "        # promediamos todos los scores e imprimimos el valor promedio\n",
    "        current_score = np.mean(scores)\n",
    "        self.history_ppl.append(current_score)\n",
    "        print(f'\\n mean perplexity: {current_score} \\n')\n",
    "\n",
    "        # chequeamos si tenemos que detener el entrenamiento\n",
    "        if current_score < self.min_score:\n",
    "          self.min_score = current_score\n",
    "          self.model.save(self.model_name)\n",
    "          print(\"Saved new model!\")\n",
    "          self.patience_counter = 0\n",
    "        else:\n",
    "          self.patience_counter += 1\n",
    "          if self.patience_counter == self.patience:\n",
    "            print(\"Stopping training...\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Zd2OkfQYs2Q7",
    "outputId": "dc967612-baa6-4314-e28c-df41e2be511f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001B[38;5;33mSimpleRNN\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)      │        \u001B[38;5;34m52,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │        \u001B[38;5;34m12,462\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,462</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m65,062\u001B[0m (254.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,062</span> (254.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m65,062\u001B[0m (254.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,062</span> (254.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
    "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HBZIwR0gruA"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"biblia_model.keras\""
   ],
   "metadata": {
    "id": "HssahQjbx6pq"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQq1PHDkxDvN",
    "outputId": "8d847ce1-3dbc-4497-ee1e-39107ec197bf",
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 2.4303\n",
      " mean perplexity: 6.5552245432680305 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 44ms/step - loss: 2.4299\n",
      "Epoch 2/20\n",
      "\u001B[1m775/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8085\n",
      " mean perplexity: 5.514331385222349 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 19ms/step - loss: 1.8082\n",
      "Epoch 3/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 1.6525\n",
      " mean perplexity: 5.079603344743902 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 21ms/step - loss: 1.6525\n",
      "Epoch 4/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5749\n",
      " mean perplexity: 4.926017561825839 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 19ms/step - loss: 1.5749\n",
      "Epoch 5/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.5297\n",
      " mean perplexity: 4.816973645036871 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 21ms/step - loss: 1.5297\n",
      "Epoch 6/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4990\n",
      " mean perplexity: 4.7811960415406665 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 19ms/step - loss: 1.4990\n",
      "Epoch 7/20\n",
      "\u001B[1m777/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4787\n",
      " mean perplexity: 4.7653323390267115 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 21ms/step - loss: 1.4787\n",
      "Epoch 8/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4637\n",
      " mean perplexity: 4.829765783656727 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 21ms/step - loss: 1.4637\n",
      "Epoch 9/20\n",
      "\u001B[1m775/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4510\n",
      " mean perplexity: 4.736728883331472 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 19ms/step - loss: 1.4510\n",
      "Epoch 10/20\n",
      "\u001B[1m777/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4431\n",
      " mean perplexity: 4.5594225845553655 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 21ms/step - loss: 1.4431\n",
      "Epoch 11/20\n",
      "\u001B[1m775/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4336\n",
      " mean perplexity: 4.607478496161375 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 19ms/step - loss: 1.4336\n",
      "Epoch 12/20\n",
      "\u001B[1m777/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4271\n",
      " mean perplexity: 4.704407061230053 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 21ms/step - loss: 1.4271\n",
      "Epoch 13/20\n",
      "\u001B[1m777/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4185\n",
      " mean perplexity: 4.582149145819924 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 21ms/step - loss: 1.4185\n",
      "Epoch 14/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4156\n",
      " mean perplexity: 4.839408257332715 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 21ms/step - loss: 1.4156\n",
      "Epoch 15/20\n",
      "\u001B[1m776/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.4100\n",
      " mean perplexity: 4.802405951781706 \n",
      "\n",
      "Stopping training...\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 19ms/step - loss: 1.4100\n"
     ]
    }
   ],
   "source": [
    "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
    "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
    "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
    "history_ppl = []\n",
    "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val, history_ppl, model_name)], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "K30JHB3Dv-mx",
    "outputId": "b229a732-641d-470f-ee80-4f25edf85e2a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "epoch_count = range(1, len(history_ppl) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Rhy5hZN38qfO"
   },
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model = keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN6Fg_BsxJe6"
   },
   "source": [
    "\n",
    "### Predicción del próximo caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBvKHFPmzpy2",
    "outputId": "9d650df5-f06c-4ee6-8b08-ac8ab0200bda"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.9/46.9 MB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m322.2/322.2 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m95.2/95.2 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.5/11.5 MB\u001B[0m \u001B[31m37.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.5/62.5 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "# Se puede usar gradio para probar el modelo\n",
    "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
    "# https://gradio.app/\n",
    "\n",
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aunque es posible, quizás no es tan interesante ver solamente el próximo caractere propuesto por el modelo, por tanto no exploraremos mucho la predicción de a un caracter."
   ],
   "metadata": {
    "id": "_ovs-M8a0J6j"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HNyBykvhzs7-",
    "outputId": "9f91d6f3-f1ec-4033-ceba-eab2a298a2d7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
      "* Running on public URL: https://4571befe5043bda86b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://4571befe5043bda86b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://4571befe5043bda86b.gradio.live\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def model_response(human_text):\n",
    "\n",
    "    # Encodeamos\n",
    "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
    "    # Si tienen distinto largo\n",
    "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
    "\n",
    "    # Predicción softmax\n",
    "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
    "\n",
    "    # Debemos buscar en el vocabulario el caracter\n",
    "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
    "    out_word = ''\n",
    "    out_word = idx2char[y_hat]\n",
    "\n",
    "    # Agrego el caracter a la frase predicha\n",
    "    return human_text + out_word\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=model_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCeMWWupxN1-"
   },
   "source": [
    "### Generación de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bwbS_pfhxvB3"
   },
   "outputs": [],
   "source": [
    "def generate_seq(model, seed_text, max_length, n_tokens):\n",
    "    \"\"\"\n",
    "        Exec model sequence prediction\n",
    "\n",
    "        Args:\n",
    "            model (keras): modelo entrenado\n",
    "            seed_text (string): texto de entrada (input_seq)\n",
    "            max_length (int): máxima longitud de la sequencia de entrada\n",
    "            n_tokens (int): números de caracteres a agregar a la sequencia de entrada\n",
    "        returns:\n",
    "            output_text (string): sentencia con las \"n_tokens\" agregadas\n",
    "    \"\"\"\n",
    "    output_text = seed_text\n",
    "\t  # generamos una cantidad fija de caracteres\n",
    "    for _ in range(n_tokens):\n",
    "\t\t    # Encodeamos\n",
    "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
    "\t\t    # Si tienen distinto largo\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "\t\t    # Predicción softmax\n",
    "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
    "\t\t    # Vamos concatenando las predicciones\n",
    "        out_word = ''\n",
    "\n",
    "        out_word = idx2char[y_hat]\n",
    "\n",
    "\t\t    # Agrego los caracteres a la frase predicha\n",
    "        output_text += out_word\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_text_1='y entonces moisés '"
   ],
   "metadata": {
    "id": "NMaQ8A7c1nqy"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JoFqRC5pxzqS",
    "outputId": "bdd6a9ad-17b7-4cd6-dd5b-6ce21a7faa6c"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'y entonces moisés a la entrada de la tienda del encuentro y lo que la piel, en el sacerdote lo que se acercarán la car'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "generate_seq(model, input_text_1, max_length=max_context_size, n_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "La primera conclusión es que, aunque la frase generada tenga un sentido sintáctico, formando palabras reales que figuran en la biblia, no se cuenta con un sentido semántico."
   ],
   "metadata": {
    "id": "yd5J5QLa0zhz"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drJ6xn5qW1Hl"
   },
   "source": [
    "###  Beam search y muestreo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_vovn9XZW1Hl"
   },
   "outputs": [],
   "source": [
    "# funcionalidades para hacer encoding y decoding\n",
    "def encode(text,max_length=max_context_size):\n",
    "\n",
    "    encoded = [char2idx[ch] for ch in text]\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def decode(seq):\n",
    "    return ''.join([idx2char[ch] for ch in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I_lZiQwkW1Hl"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# función que selecciona candidatos para el beam search\n",
    "def select_candidates(pred, num_beams, vocab_size, history_probs, history_tokens, temp, mode):\n",
    "\n",
    "  # colectar todas las probabilidades para la siguiente búsqueda\n",
    "  pred_large = []\n",
    "\n",
    "  for idx,pp in enumerate(pred):\n",
    "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
    "\n",
    "  pred_large = np.array(pred_large)\n",
    "\n",
    "  # criterio de selección\n",
    "  if mode == 'det':\n",
    "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
    "  elif mode == 'sto':\n",
    "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
    "  else:\n",
    "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
    "\n",
    "  # traducir a índices de token en el vocabulario\n",
    "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
    "                        np.array([idx_select%vocab_size]).T),\n",
    "                      axis=1)\n",
    "\n",
    "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
    "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
    "\n",
    "\n",
    "def beam_search(model, num_beams, num_tokens, input, temp=1, mode='det'):\n",
    "\n",
    "    # first iteration\n",
    "\n",
    "    # encode\n",
    "    encoded = encode(input)\n",
    "\n",
    "    # first prediction\n",
    "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
    "\n",
    "    # get vocabulary size\n",
    "    vocab_size = y_hat.shape[0]\n",
    "\n",
    "    # initialize history\n",
    "    history_probs = [0]*num_beams\n",
    "    history_tokens = [encoded[0]]*num_beams\n",
    "\n",
    "    # select num_beams candidates\n",
    "    history_probs, history_tokens = select_candidates([y_hat],\n",
    "                                        num_beams,\n",
    "                                        vocab_size,\n",
    "                                        history_probs,\n",
    "                                        history_tokens,\n",
    "                                        temp,\n",
    "                                        mode)\n",
    "\n",
    "    # beam search loop\n",
    "    for i in range(num_tokens-1):\n",
    "\n",
    "      preds = []\n",
    "\n",
    "      for hist in history_tokens:\n",
    "\n",
    "        # actualizar secuencia de tokens\n",
    "        input_update = np.array([hist[i+1:]]).copy()\n",
    "\n",
    "        # predicción\n",
    "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
    "\n",
    "        preds.append(y_hat)\n",
    "\n",
    "      history_probs, history_tokens = select_candidates(preds,\n",
    "                                                        num_beams,\n",
    "                                                        vocab_size,\n",
    "                                                        history_probs,\n",
    "                                                        history_tokens,\n",
    "                                                        temp,\n",
    "                                                        mode)\n",
    "\n",
    "    return history_tokens[:,-(len(input)+num_tokens):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeLqAoOYW1Hm"
   },
   "outputs": [],
   "source": [
    "# predicción con beam search\n",
    "salidas = beam_search(model, num_beams=10, num_tokens=100, input=input_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8HQoLhw-NYg",
    "outputId": "77d19738-7875-4427-dfbc-b1b9cf9ae851"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([48,  0, 29, 38, 44, 39, 38, 27, 29, 43,  0, 37, 39, 33, 43, 55, 43,\n",
       "        0, 28, 29,  0, 36, 25,  0, 44, 33, 29, 38, 28, 25,  0, 28, 29, 36,\n",
       "        0, 29, 38, 27, 45, 29, 38, 44, 42, 39,  0, 40, 25, 42, 25,  0, 29,\n",
       "       36,  0, 43, 25, 27, 29, 42, 28, 39, 44, 29,  0, 36, 39,  0, 41, 45,\n",
       "       29, 28, 25, 42, 54,  0, 33, 37, 40, 45, 42, 39,  0, 32, 25, 43, 44,\n",
       "       25,  0, 36, 25,  0, 44, 33, 29, 38, 28, 25,  0, 28, 29, 36,  0, 29,\n",
       "       38, 27, 45, 29, 38, 44, 42, 39,  0, 40, 25, 42, 25,  0, 29, 36])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "salidas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2S3_I3S1W1Hm"
   },
   "outputs": [],
   "source": [
    "salidas_decoded = [decode(salida) for salida in salidas]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for salida in salidas_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "id": "eUoBDqXnOB6Q",
    "outputId": "c1d4dbc8-3b11-4271-bb04-2057c7100169",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro por el \n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para qu\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro, con su\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para la\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro. [14] e\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro. [15] e\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro y los i\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro. [14] s\n",
      "y entonces moisés de la tienda del encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro, como s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se observa que todas las ramas cambian recién al final de la oración. Veamos probando la generación estocástica, con una temperatura más alta."
   ],
   "metadata": {
    "id": "-U3Sw3jZ2SRz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_sto = beam_search(model, num_beams=10, num_tokens=100, input=input_text_1, temp=2, mode='sto')"
   ],
   "metadata": {
    "id": "e1ZpzgT12lBy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGtWH7nl2wM0",
    "outputId": "0c714e84-1d24-41cc-ae9d-5f07bc07f908"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdosu\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdor;\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n",
      "y entonces moisés la mesa colocarán las animales de enillas que ofrecerá uno los basas. [11] pero este es el sacerdote\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nuevamente no se presenta mucha variación hasta el final de las oraciones, y se comete en este caso el error de formar palabras inexistentes."
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Propuesta de Modelos"
   ],
   "metadata": {
    "id": "9OoFVluq22sw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo con GRU\n",
    "\n",
    "Intentaremos proponer un modelo que sea ligero y eficiente, apostando por:\n",
    "\n",
    "- Embedding: Representaciones densas aprendidas (en lugar de codificación fija).\n",
    "\n",
    "- GRU: Unidades recurrentes más potentes que las SimpleRNN.\n",
    "\n",
    "Al reducir la capacidad del modelo (solo 64 unidades GRU) y cambiar la representación, puede perder capacidad expresiva."
   ],
   "metadata": {
    "id": "f_DS65uoCBQ-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "1-GX62eQWiUF",
    "outputId": "a6c751d0-ada0-476a-e97b-867156daf10b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)       │         \u001B[38;5;34m1,984\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001B[38;5;33mGRU\u001B[0m)                       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │        \u001B[38;5;34m18,816\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │         \u001B[38;5;34m4,030\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,030</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m24,830\u001B[0m (96.99 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,830</span> (96.99 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m24,830\u001B[0m (96.99 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,830</span> (96.99 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "model_improved_gru = Sequential()\n",
    "\n",
    "# Embedding en lugar de one-hot para reducir memoria necesaria, y pequeño reducir tiempo de procesamiento\n",
    "model_improved_gru.add(Input(shape=(None,))) # Secuencia de longitud variable\n",
    "model_improved_gru.add(Embedding(input_dim=vocab_size, output_dim=32))\n",
    "\n",
    "# GRU liviana por cuestiones de tiempo de procesamiento.\n",
    "model_improved_gru.add(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "\n",
    "# Capa de salida\n",
    "model_improved_gru.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Compilar\n",
    "model_improved_gru.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='rmsprop'\n",
    ")\n",
    "\n",
    "model_improved_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name_improved_gru = \"biblia_model_improved_gru.keras\""
   ],
   "metadata": {
    "id": "-UirrN8k360z"
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAbBJSXIXxPq",
    "outputId": "ba51988a-7d8e-4987-8d17-278af28a7ec3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 310ms/step - loss: 2.5215\n",
      " mean perplexity: 6.87416540926153 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m331s\u001B[0m 416ms/step - loss: 2.5210\n",
      "Epoch 2/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312ms/step - loss: 1.7693\n",
      " mean perplexity: 6.06692397811196 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m379s\u001B[0m 417ms/step - loss: 1.7693\n",
      "Epoch 3/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 1.6403\n",
      " mean perplexity: 5.889168690551411 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m343s\u001B[0m 367ms/step - loss: 1.6403\n",
      "Epoch 4/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 1.5813\n",
      " mean perplexity: 5.769571178609675 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m323s\u001B[0m 367ms/step - loss: 1.5812\n",
      "Epoch 5/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 312ms/step - loss: 1.5478\n",
      " mean perplexity: 5.768272468176755 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m324s\u001B[0m 370ms/step - loss: 1.5478\n",
      "Epoch 6/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 1.5257\n",
      " mean perplexity: 5.812094433741136 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m286s\u001B[0m 368ms/step - loss: 1.5257\n",
      "Epoch 7/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 311ms/step - loss: 1.5085\n",
      " mean perplexity: 5.91031810912219 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m323s\u001B[0m 369ms/step - loss: 1.5085\n",
      "Epoch 8/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step - loss: 1.4954\n",
      " mean perplexity: 5.990776060927998 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m320s\u001B[0m 367ms/step - loss: 1.4953\n",
      "Epoch 9/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 307ms/step - loss: 1.4864\n",
      " mean perplexity: 5.967923879623413 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m320s\u001B[0m 365ms/step - loss: 1.4864\n",
      "Epoch 10/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 305ms/step - loss: 1.4793\n",
      " mean perplexity: 5.884116866371849 \n",
      "\n",
      "Stopping training...\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m358s\u001B[0m 411ms/step - loss: 1.4793\n"
     ]
    }
   ],
   "source": [
    "history_ppl_improved_gru = []\n",
    "hist = model_improved_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val, history_ppl_improved_gru, model_name_improved_gru)], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Entrenamiento\n",
    "epoch_count = range(1, len(history_ppl) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "K4vgP9QGYOZ4",
    "outputId": "e0fc3d91-58a7-46a1-f324-c05a9ad5415f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver que en una época muy temprana deja de aprender, y la métrica de pérdida no es mejor que con el anterior modelo. Posiblemente porque simplificamos mucho el mismo con la intención de poder introducir neuronas con arquitectura GRU."
   ],
   "metadata": {
    "id": "oCrCYYSfYlmD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model_improved_gru = keras.models.load_model(model_name_improved_gru)"
   ],
   "metadata": {
    "id": "cZQKZZWZQ7PR"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_seq(model_improved_gru, input_text_1, max_length=max_context_size, n_tokens=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cokbfz5JFtQU",
    "outputId": "b0db54f2-6a36-42f8-d334-2d7e53061cf7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'y entonces moisés de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pue'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "La primera impresión es que el modelo es peor que el anterior, dada la repetición de las mismas 3 palabras, una y otra vez. Veamos que pasa con bean search y agregando luego estocacidad."
   ],
   "metadata": {
    "id": "DCg7lwizRhuy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "salidas = beam_search(model_improved_gru, num_beams=10, num_tokens=100, input=input_text_1)"
   ],
   "metadata": {
    "id": "y3zwYgCWR0bL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6KbQVc4Rxdr",
    "outputId": "da26e663-b783-4365-c2e8-26dab1f2711c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés para el sacrificio de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda de \n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda de l\n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda del \n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de los hijos de l\n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de los hijos del \n",
      "y entonces moisés de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda de la tie\n",
      "y entonces moisés de la tienda de los hijos de la tienda de la tienda de la tienda de la tienda de la tienda de la tie\n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de la tierra de l\n",
      "y entonces moisés para el sacerdote de la tienda de la tienda de la tienda de la tienda de la tienda de la tierra del \n",
      "y entonces moisés para el sacrificio de la tienda de la tienda de la tienda de la tienda de la tienda de la tienda del\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aunque se consiguen algunas opciones más variadas, eventualmente cae nuevamente en la repetición, y se continúa el problema de no conseguir un texto con sentido semántico"
   ],
   "metadata": {
    "id": "bAS_s1UdURvw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_sto = beam_search(model_improved_gru, num_beams=10, num_tokens=100, input=input_text_1, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgCTK6B2R9Z5",
    "outputId": "996ae0c1-4439-44dd-e0a1-0730de8ba685"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israel\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israer\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israel\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israel\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los dios,.\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israel\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israel\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israng\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israer\n",
      "y entonces moisés de los compuran de yahveh, no hizo sobre tu puro de los pecasado. [31] del sacrificio, en los israeg\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resulta sorprendente que se pierda la variedad adquirida con bean search, a pesar de agregar estocacidad y temperatura, que para el anterior modelo, había introducido bastante más variedad."
   ],
   "metadata": {
    "id": "x84Fh4pPY2Ps"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo con LSTM\n",
    "\n",
    "Intentaremos ahora con un modelo que sea una alternativa sólida al baseline, apostando por un LSTM liviano con codificación explícita. Si bien no introduce cambios estructurales radicales, es una opción que busca equilibrio entre potencia y simplicidad, para ver si se puede evitar una arquitectura más profunda."
   ],
   "metadata": {
    "id": "3l8i1m_6Dh7P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_improved_lstm = Sequential()\n",
    "\n",
    "# Codificación one-hot con TimeDistributed\n",
    "model_improved_lstm.add(TimeDistributed(\n",
    "    CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\"),\n",
    "    input_shape=(None, 1)\n",
    "))\n",
    "\n",
    "# LSTM liviana\n",
    "model_improved_lstm.add(LSTM(\n",
    "    units=128,                  # Suficientemente potente, pero más liviana que 200-256\n",
    "    return_sequences=True,\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.1\n",
    "))\n",
    "\n",
    "# Capa de salida\n",
    "model_improved_lstm.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Compilación\n",
    "model_improved_lstm.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='rmsprop'\n",
    ")\n",
    "\n",
    "model_improved_lstm.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "8_Gyli6IZGp3",
    "outputId": "79039d34-7745-4689-a085-1806a8a83845"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │        \u001B[38;5;34m97,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │         \u001B[38;5;34m7,998\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">97,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,998</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m105,790\u001B[0m (413.24 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,790</span> (413.24 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m105,790\u001B[0m (413.24 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,790</span> (413.24 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name_improved_lstm = \"biblia_model_improved_lstm.keras\""
   ],
   "metadata": {
    "id": "Ak1FQxgkZgmB"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history_ppl_improved_lstm = []\n",
    "hist = model_improved_lstm.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val, history_ppl_improved_lstm, model_name_improved_lstm)], batch_size=256)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqJMn_qWZkYg",
    "outputId": "2d2205dc-7ff3-4702-b5f8-33618e7a5cda"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 900ms/step - loss: 2.8421\n",
      " mean perplexity: 8.967343544960022 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m792s\u001B[0m 1s/step - loss: 2.8417 \n",
      "Epoch 2/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 929ms/step - loss: 2.1493\n",
      " mean perplexity: 7.544358092004603 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m764s\u001B[0m 982ms/step - loss: 2.1493\n",
      "Epoch 3/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904ms/step - loss: 2.0115\n",
      " mean perplexity: 6.942538561604239 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m785s\u001B[0m 1s/step - loss: 2.0115 \n",
      "Epoch 4/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904ms/step - loss: 1.9311\n",
      " mean perplexity: 6.651729957623915 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m744s\u001B[0m 957ms/step - loss: 1.9311\n",
      "Epoch 5/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955ms/step - loss: 1.8717\n",
      " mean perplexity: 6.43114350492304 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m784s\u001B[0m 1s/step - loss: 1.8717 \n",
      "Epoch 6/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 914ms/step - loss: 1.8234\n",
      " mean perplexity: 6.3272823095321655 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m767s\u001B[0m 962ms/step - loss: 1.8234\n",
      "Epoch 7/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912ms/step - loss: 1.7825\n",
      " mean perplexity: 6.18733510537581 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m803s\u001B[0m 965ms/step - loss: 1.7825\n",
      "Epoch 8/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926ms/step - loss: 1.7453\n",
      " mean perplexity: 6.0892801078883085 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m809s\u001B[0m 974ms/step - loss: 1.7453\n",
      "Epoch 9/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 914ms/step - loss: 1.7134\n",
      " mean perplexity: 6.02421737909317 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m794s\u001B[0m 964ms/step - loss: 1.7134\n",
      "Epoch 10/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 902ms/step - loss: 1.6856\n",
      " mean perplexity: 5.898144336180254 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m795s\u001B[0m 955ms/step - loss: 1.6856\n",
      "Epoch 11/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 916ms/step - loss: 1.6603\n",
      " mean perplexity: 5.835627193884416 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m750s\u001B[0m 964ms/step - loss: 1.6603\n",
      "Epoch 12/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 929ms/step - loss: 1.6401\n",
      " mean perplexity: 5.690071073445407 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m813s\u001B[0m 978ms/step - loss: 1.6401\n",
      "Epoch 13/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 919ms/step - loss: 1.6223\n",
      " mean perplexity: 5.667487595298073 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m793s\u001B[0m 966ms/step - loss: 1.6223\n",
      "Epoch 14/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937ms/step - loss: 1.6045\n",
      " mean perplexity: 5.686413954604756 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m821s\u001B[0m 990ms/step - loss: 1.6045\n",
      "Epoch 15/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 908ms/step - loss: 1.5901\n",
      " mean perplexity: 5.623782672665336 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m774s\u001B[0m 955ms/step - loss: 1.5901\n",
      "Epoch 16/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 928ms/step - loss: 1.5768\n",
      " mean perplexity: 5.570872365344655 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m763s\u001B[0m 981ms/step - loss: 1.5768\n",
      "Epoch 17/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 913ms/step - loss: 1.5633\n",
      " mean perplexity: 5.500382048433477 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m752s\u001B[0m 966ms/step - loss: 1.5633\n",
      "Epoch 18/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 920ms/step - loss: 1.5505\n",
      " mean perplexity: 5.454412691159682 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m807s\u001B[0m 973ms/step - loss: 1.5505\n",
      "Epoch 19/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926ms/step - loss: 1.5382\n",
      " mean perplexity: 5.512413967739452 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m762s\u001B[0m 979ms/step - loss: 1.5382\n",
      "Epoch 20/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912ms/step - loss: 1.5272\n",
      " mean perplexity: 5.514256704937328 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m787s\u001B[0m 960ms/step - loss: 1.5272\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model_improved_lstm = keras.models.load_model(model_name_improved_lstm)"
   ],
   "metadata": {
    "id": "V_SA7IzsuQ10"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_seq(model_improved_lstm, input_text_1, max_length=max_context_size, n_tokens=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jQP6EmAMuWa3",
    "outputId": "ede8d289-4516-47ea-b31c-fa49c8c209c7"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del en'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "salidas = beam_search(model_improved_lstm, num_beams=10, num_tokens=100, input=input_text_1)\n",
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJ9kt-qhuYjz",
    "outputId": "dd918ba0-6848-4644-cd8b-9fc4904c1029"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés de la tienda de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la \n",
      "y entonces moisés de la tienda del encuentro de la tienda de la tienda del encuentro de la tienda del encuentro de la \n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda de la tienda del encuentro de la \n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del en\n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda de la \n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del sa\n",
      "y entonces moisés de la tienda de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de los\n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del ca\n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del al\n",
      "y entonces moisés de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del el\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_sto = beam_search(model_improved_lstm, num_beams=10, num_tokens=100, input=input_text_1, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqxIyskCubwE",
    "outputId": "f707351c-6c7c-41d2-beb6-80a59f82ec7a"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [9\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. y \n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. y \n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [n\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [2\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [2\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [1\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. y.\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [6\n",
      "y entonces moisés a los israelitas, de sus honos los hijos y los entras y tomas trabajos que habla sobre el pacado. [9\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se repiten los mismos problemas que con el modelo usando arquitectura GRU para las neuronas."
   ],
   "metadata": {
    "id": "D-yaqvL1wJbA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos que ocurre con las 3 redes, con un par de inputs distintos, con distintas longitudes y distinta cantidad de tokens a generar:"
   ],
   "metadata": {
    "id": "AdonjR6Pw2P1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_text_2 = \"y descendió fuego del cielo, y consumió el altar y el sacrificio, \"\n",
    "input_text_3 = \"y habló dios, diciendo \"\n",
    "input_text_4 = \"y \""
   ],
   "metadata": {
    "id": "utAqYpZqwPuy"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inputs = [\n",
    "    (\"input_text_2\", input_text_2, 150),\n",
    "    (\"input_text_3\", input_text_3, 40),\n",
    "    (\"input_text_4\", input_text_4, 100),\n",
    "]\n",
    "\n",
    "models = [\n",
    "    (\"model\", model),\n",
    "    (\"model_improved_gru\", model_improved_gru),\n",
    "    (\"model_improved_lstm\", model_improved_lstm),\n",
    "]"
   ],
   "metadata": {
    "id": "EA8CrMCB05ZM"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, width=120):\n",
    "    for line in textwrap.wrap(text, width):\n",
    "        print(line)\n",
    "\n",
    "for input_name, input_text, n_tokens in inputs:\n",
    "    print(f\"\\n\\n{'='*40}\")\n",
    "    print(f\"PROCESSING {input_name.upper()}\")\n",
    "    print(f\"{'='*40}\\n\")\n",
    "\n",
    "    # ----- SEQUENTIAL GENERATION -----\n",
    "    print(\">>> SEQUENTIAL GENERATION (generate_seq)\\n\")\n",
    "    for model_name, model_instance in models:\n",
    "        print(f\"--- {model_name} ---\")\n",
    "        print(generate_seq(model_instance, input_text, max_length=max_context_size, n_tokens=n_tokens))\n",
    "        print()\n",
    "\n",
    "    # ----- BEAM SEARCH (DETERMINISTIC) -----\n",
    "    print(\">>> BEAM SEARCH (deterministic)\\n\")\n",
    "    for model_name, model_instance in models:\n",
    "        print(f\"--- {model_name} ---\")\n",
    "        salidas = beam_search(model_instance, num_beams=10, num_tokens=n_tokens, input=input_text)\n",
    "        salidas_decoded = [decode(salida) for salida in salidas]\n",
    "        for i, salida in enumerate(salidas_decoded):\n",
    "            print(f\"[Beam {i+1}]\")\n",
    "            print_wrapped(salida)\n",
    "        print()\n",
    "\n",
    "    # ----- BEAM SEARCH (STOCHASTIC) -----\n",
    "    print(\">>> BEAM SEARCH (stochastic, temp=2, mode='sto')\\n\")\n",
    "    for model_name, model_instance in models:\n",
    "        print(f\"--- {model_name} ---\")\n",
    "        salidas_sto = beam_search(model_instance, num_beams=10, num_tokens=n_tokens, input=input_text, temp=2, mode='sto')\n",
    "        salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "        for i, salida in enumerate(salidas_sto_decoded):\n",
    "            print(f\"[Stochastic Beam {i+1}]\")\n",
    "            print_wrapped(salida)\n",
    "        print()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "FdGt89t_yfWI",
    "outputId": "7dc842c5-c522-442a-b1b3-8e515f658596"
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "PROCESSING INPUT_TEXT_2\n",
      "========================================\n",
      "\n",
      ">>> SEQUENTIAL GENERATION (generate_seq)\n",
      "\n",
      "--- model ---\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, pero el sacerdote lo que se acercarán la carnero de la tienda del encuentro y lo que la piel, en el sacerdote lo que se acercarán la carnero de la tie\n",
      "\n",
      "--- model_improved_gru ---\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pu\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro d\n",
      "\n",
      ">>> BEAM SEARCH (deterministic)\n",
      "\n",
      "--- model ---\n",
      "[Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo quemar\n",
      "[Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que se\n",
      "[Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que ha\n",
      "[Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote los israe\n",
      "[Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo quedar\n",
      "[Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que es\n",
      "[Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que le\n",
      "[Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que la\n",
      "[Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que yo\n",
      "[Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, como sacrificio por el pecado de la tienda del\n",
      "encuentro para el sacerdote lo quedará impuro hasta la tienda del encuentro para el sacerdote lo que no\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la\n",
      "[Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de los\n",
      "[Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de los\n",
      "[Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de los hijos de los\n",
      "[Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote en el\n",
      "[Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de la p\n",
      "[Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de la t\n",
      "[Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sa\n",
      "[Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de los hijos de la p\n",
      "[Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, para el sacerdote del sacerdote del sacerdote del\n",
      "sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de los hijos de la t\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote de la tienda del encuentro de la\n",
      "tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentr\n",
      "[Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, de la tienda del encuentro de la tienda del encuentro\n",
      "de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda de\n",
      "[Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro,\n",
      "[Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro.\n",
      "[Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro d\n",
      "[Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote de la tienda del encuentro de la\n",
      "tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del sacerdot\n",
      "[Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro y\n",
      "[Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del sacerdote l\n",
      "[Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro p\n",
      "[Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda\n",
      "del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del sacerdote d\n",
      "\n",
      ">>> BEAM SEARCH (stochastic, temp=2, mode='sto')\n",
      "\n",
      "--- model ---\n",
      "[Stochastic Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se da\n",
      "[Stochastic Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se as\n",
      "[Stochastic Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se ar\n",
      "[Stochastic Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se la\n",
      "[Stochastic Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se af\n",
      "[Stochastic Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se lá\n",
      "[Stochastic Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y sabrá\n",
      "[Stochastic Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se aq\n",
      "[Stochastic Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se an\n",
      "[Stochastic Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, [24] pero si un cubrirás a yahveh, el sacerdote\n",
      "delante de yahveh, para el pecado, y lo exterminará sobre la calabras, el sacerdote el pueblo, y se lo\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Stochastic Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del egla\n",
      "[Stochastic Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del el p\n",
      "[Stochastic Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del egle\n",
      "[Stochastic Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del camó\n",
      "[Stochastic Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del cagu\n",
      "[Stochastic Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del cabó\n",
      "[Stochastic Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del camp\n",
      "[Stochastic Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del cabé\n",
      "[Stochastic Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del el y\n",
      "[Stochastic Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, y es el los hijos y se haya es el altar de los hijos\n",
      "de los desiertas entrada aarón de la ofrecerá con cuando de la incibicio y con los hijos del el t\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Stochastic Beam 1]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hast\n",
      "[Stochastic Beam 2]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh haci\n",
      "[Stochastic Beam 3]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hast\n",
      "[Stochastic Beam 4]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hay;\n",
      "[Stochastic Beam 5]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh. tab\n",
      "[Stochastic Beam 6]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hay\n",
      "[Stochastic Beam 7]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hace\n",
      "[Stochastic Beam 8]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hisü\n",
      "[Stochastic Beam 9]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh hasc\n",
      "[Stochastic Beam 10]\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacerdote yahveh. [7] yahveh el altar porque\n",
      "yahveh había la piel, es la camera del mano formal, sin el mecho y mojarás de acertado yahveh haya\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "PROCESSING INPUT_TEXT_3\n",
      "========================================\n",
      "\n",
      ">>> SEQUENTIAL GENERATION (generate_seq)\n",
      "\n",
      "--- model ---\n",
      "y habló dios, diciendo en el altar de los israelitas y los isra\n",
      "\n",
      "--- model_improved_gru ---\n",
      "y habló dios, diciendo de la pueblo de la pueblo de la pueblo d\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "y habló dios, diciendo en el pecado de la tienda del encuentro \n",
      "\n",
      ">>> BEAM SEARCH (deterministic)\n",
      "\n",
      "--- model ---\n",
      "[Beam 1]\n",
      "y habló dios, diciendo en la tienda del encuentro por el pecado\n",
      "[Beam 2]\n",
      "y habló dios, diciendo en la tienda del encuentro para el altar\n",
      "[Beam 3]\n",
      "y habló dios, diciendo en la tienda del encuentro para el sacer\n",
      "[Beam 4]\n",
      "y habló dios, diciendo en la tienda del encuentro y los israeli\n",
      "[Beam 5]\n",
      "y habló dios, diciendo en la tienda del encuentro para el pecad\n",
      "[Beam 6]\n",
      "y habló dios, diciendo en la tienda del encuentro para que se a\n",
      "[Beam 7]\n",
      "y habló dios, diciendo en la tienda del encuentro para el sebo\n",
      "[Beam 8]\n",
      "y habló dios, diciendo en la tienda del encuentro para que se h\n",
      "[Beam 9]\n",
      "y habló dios, diciendo en la tienda del encuentro para que habí\n",
      "[Beam 10]\n",
      "y habló dios, diciendo en la tienda del encuentro para que esta\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Beam 1]\n",
      "y habló dios, diciendo del sacerdote de la tienda de la tienda\n",
      "[Beam 2]\n",
      "y habló dios, diciendo del sacerdote de los hijos de la tienda\n",
      "[Beam 3]\n",
      "y habló dios, diciendo del sacerdote de la tienda de los hijos\n",
      "[Beam 4]\n",
      "y habló dios, diciendo el sacerdote de la tienda de la tienda d\n",
      "[Beam 5]\n",
      "y habló dios, diciendo el sacerdote de la tienda de los hijos d\n",
      "[Beam 6]\n",
      "y habló dios, diciendo del sacerdote de la tienda de la tierra\n",
      "[Beam 7]\n",
      "y habló dios, diciendo del sacrificio de la tienda de la tienda\n",
      "[Beam 8]\n",
      "y habló dios, diciendo del sacerdote de los hijos de la tierra\n",
      "[Beam 9]\n",
      "y habló dios, diciendo el sacerdote de la tienda de los hijos,\n",
      "[Beam 10]\n",
      "y habló dios, diciendo el sacerdote de la tienda de la tierra d\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Beam 1]\n",
      "y habló dios, diciendo de la tienda de la tienda del encuentro\n",
      "[Beam 2]\n",
      "y habló dios, diciendo de la tienda de la tienda del sacerdote\n",
      "[Beam 3]\n",
      "y habló dios, diciendo de la tienda del encuentro de la tienda\n",
      "[Beam 4]\n",
      "y habló dios, diciendo de la tienda de la tienda del encuentro,\n",
      "[Beam 5]\n",
      "y habló dios, diciendo de la tienda de la tienda del encuentro.\n",
      "[Beam 6]\n",
      "y habló dios, diciendo de la tienda del encuentro por el pecado\n",
      "[Beam 7]\n",
      "y habló dios, diciendo de la tienda del encuentro por el pueblo\n",
      "[Beam 8]\n",
      "y habló dios, diciendo de la tienda del encuentro por el sacerd\n",
      "[Beam 9]\n",
      "y habló dios, diciendo de la tienda de la tienda del encuentros\n",
      "[Beam 10]\n",
      "y habló dios, diciendo de la tienda del encuentro de la tierra\n",
      "\n",
      ">>> BEAM SEARCH (stochastic, temp=2, mode='sto')\n",
      "\n",
      "--- model ---\n",
      "[Stochastic Beam 1]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día segun.\n",
      "[Stochastic Beam 2]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será e\n",
      "[Stochastic Beam 3]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será l\n",
      "[Stochastic Beam 4]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día serenc\n",
      "[Stochastic Beam 5]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será p\n",
      "[Stochastic Beam 6]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día segunm\n",
      "[Stochastic Beam 7]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será d\n",
      "[Stochastic Beam 8]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será f\n",
      "[Stochastic Beam 9]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día segue,\n",
      "[Stochastic Beam 10]\n",
      "y habló dios, diciendo en el sacerdote lo quemará el día será é\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Stochastic Beam 1]\n",
      "y habló dios, diciendo en la carne de los la tienda del anchos\n",
      "[Stochastic Beam 2]\n",
      "y habló dios, diciendo en la carne de los la tienda del anchos\n",
      "[Stochastic Beam 3]\n",
      "y habló dios, diciendo en la carne de los la tienda del ancho.\n",
      "[Stochastic Beam 4]\n",
      "y habló dios, diciendo en la carne de los la tienda del anime e\n",
      "[Stochastic Beam 5]\n",
      "y habló dios, diciendo en la carne de los la tienda del ancesdt\n",
      "[Stochastic Beam 6]\n",
      "y habló dios, diciendo en la carne de los la tienda del animías\n",
      "[Stochastic Beam 7]\n",
      "y habló dios, diciendo en la carne de los la tienda del animías\n",
      "[Stochastic Beam 8]\n",
      "y habló dios, diciendo en la carne de los la tienda del anchos\n",
      "[Stochastic Beam 9]\n",
      "y habló dios, diciendo en la carne de los la tienda del anime f\n",
      "[Stochastic Beam 10]\n",
      "y habló dios, diciendo en la carne de los la tienda del anchos\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Stochastic Beam 1]\n",
      "y habló dios, diciendo porque el día de la cabera de su dierno\n",
      "[Stochastic Beam 2]\n",
      "y habló dios, diciendo porque el día de la cabera de su marlaca\n",
      "[Stochastic Beam 3]\n",
      "y habló dios, diciendo porque el día de la cabera de su marla e\n",
      "[Stochastic Beam 4]\n",
      "y habló dios, diciendo porque el día de la cabera de su diera e\n",
      "[Stochastic Beam 5]\n",
      "y habló dios, diciendo porque el día de la cabera de su dierno,\n",
      "[Stochastic Beam 6]\n",
      "y habló dios, diciendo porque el día de la cabera de su marla d\n",
      "[Stochastic Beam 7]\n",
      "y habló dios, diciendo porque el día de la cabera de su dierno;\n",
      "[Stochastic Beam 8]\n",
      "y habló dios, diciendo porque el día de la cabera de su marla a\n",
      "[Stochastic Beam 9]\n",
      "y habló dios, diciendo porque el día de la cabera de su diera d\n",
      "[Stochastic Beam 10]\n",
      "y habló dios, diciendo porque el día de la cabera de su dierno.\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "PROCESSING INPUT_TEXT_4\n",
      "========================================\n",
      "\n",
      ">>> SEQUENTIAL GENERATION (generate_seq)\n",
      "\n",
      "--- model ---\n",
      "y se ha extendido en el altar de los israelitas y los israelitas y los israelitas y los israelitas y l\n",
      "\n",
      "--- model_improved_gru ---\n",
      "y la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo de la pueblo\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "y el sacerdote lo que se ha para el pecado de la tienda del encuentro de la tienda del encuentro de la\n",
      "\n",
      ">>> BEAM SEARCH (deterministic)\n",
      "\n",
      "--- model ---\n",
      "[Beam 1]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro. [\n",
      "[Beam 2]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro y\n",
      "[Beam 3]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro, p\n",
      "[Beam 4]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro pa\n",
      "[Beam 5]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro, e\n",
      "[Beam 6]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro de\n",
      "[Beam 7]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará el sacerdote los israelitas,\n",
      "[Beam 8]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro, c\n",
      "[Beam 9]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro po\n",
      "[Beam 10]\n",
      "y los israelitas de la tienda del encuentro para el sacerdote lo quemará en la tienda del encuentro co\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Beam 1]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de\n",
      "[Beam 2]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote la\n",
      "[Beam 3]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote el\n",
      "[Beam 4]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de l\n",
      "[Beam 5]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote en\n",
      "[Beam 6]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del\n",
      "[Beam 7]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda del\n",
      "[Beam 8]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de los hijos de l\n",
      "[Beam 9]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de la tienda de la\n",
      "[Beam 10]\n",
      "y el sacerdote del sacerdote del sacerdote del sacerdote del sacerdote de la tienda de los hijos de la\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Beam 1]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de l\n",
      "[Beam 2]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro del\n",
      "[Beam 3]\n",
      "y los israelitas de la tienda de la tienda del encuentro de la tienda del encuentro de la tienda del e\n",
      "[Beam 4]\n",
      "y los israelitas de la tienda del encuentro de la tienda de la tienda del encuentro de la tienda del e\n",
      "[Beam 5]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda de la tienda del e\n",
      "[Beam 6]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda del sacerdote lo q\n",
      "[Beam 7]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro y lo\n",
      "[Beam 8]\n",
      "y los israelitas de la tienda del encuentro de la tienda del encuentro de la tienda del sacerdote de l\n",
      "[Beam 9]\n",
      "y los israelitas de la tienda de la tienda del encuentro de la tienda del encuentro de la tienda del s\n",
      "[Beam 10]\n",
      "y los israelitas de la tienda del encuentro de la tienda de la tienda del encuentro de la tienda del s\n",
      "\n",
      ">>> BEAM SEARCH (stochastic, temp=2, mode='sto')\n",
      "\n",
      "--- model ---\n",
      "[Stochastic Beam 1]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón y\n",
      "[Stochastic Beam 2]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón,\n",
      "[Stochastic Beam 3]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón:\n",
      "[Stochastic Beam 4]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón c\n",
      "[Stochastic Beam 5]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón l\n",
      "[Stochastic Beam 6]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón p\n",
      "[Stochastic Beam 7]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón:\n",
      "[Stochastic Beam 8]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón.\n",
      "[Stochastic Beam 9]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón,\n",
      "[Stochastic Beam 10]\n",
      "y se acercará. [13] el santo al monte cominada de su calmano de los israelitas de la tierra de aarón e\n",
      "\n",
      "--- model_improved_gru ---\n",
      "[Stochastic Beam 1]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la peco\n",
      "[Stochastic Beam 2]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la holor\n",
      "[Stochastic Beam 3]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la holoc\n",
      "[Stochastic Beam 4]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la holoc\n",
      "[Stochastic Beam 5]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la holot\n",
      "[Stochastic Beam 6]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la holos\n",
      "[Stochastic Beam 7]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la pecod\n",
      "[Stochastic Beam 8]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la peco,\n",
      "[Stochastic Beam 9]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la gano\n",
      "[Stochastic Beam 10]\n",
      "y se herio con los sobre el sebon de ellos. [21] yahveh. [21] no hasta yahveh había yahveh de la pusso\n",
      "\n",
      "--- model_improved_lstm ---\n",
      "[Stochastic Beam 1]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del mar\n",
      "[Stochastic Beam 2]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del man\n",
      "[Stochastic Beam 3]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del map\n",
      "[Stochastic Beam 4]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del sic\n",
      "[Stochastic Beam 5]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del man\n",
      "[Stochastic Beam 6]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del man\n",
      "[Stochastic Beam 7]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del mig\n",
      "[Stochastic Beam 8]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del man\n",
      "[Stochastic Beam 9]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del qué\n",
      "[Stochastic Beam 10]\n",
      "y ella por uno se propicio. [27] no sobre el daver para, los hijos, y el pueblo. [12] el secer del mae\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el input \"y descendió fuego del cielo, y consumió el altar y el sacrificio, \", parece que incluso el modelo original es el mejor. Es el que más caracteres genera sin caer en repetción, y pronpone algunas palabras interesantes relacionadas con el input como \"cabra\". El resto de los modelos caen rápidamente en repetición. Para la generación estocástica se logra reducir un poco esto, pero se introduce el problema de generar palabras inexistentes."
   ],
   "metadata": {
    "id": "q_7UuvZoZAjd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el input \"y habló dios, diciendo \" se vuelve a repetir la problemática de los modelos, y queda en evidencia además del uso de la mayoría de palabras sin importar el contexto. En este caso hace sentido mencionar \"sacerdote\", pero vemos que se ha utilizado en otro contexto y además se vuelve a repetir \"tiendas, \"sacrificio\"..."
   ],
   "metadata": {
    "id": "nxPGoIrxZ5O8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, para el input más abierto \"y \" cada modelo modifica la desición de como completar, pero como es de esperar, utilizan las mismas palabras que para los otros contextos."
   ],
   "metadata": {
    "id": "A4iJ9lAGaUei"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo con doble capa LSTM\n",
    "\n",
    "Finalmente, intentemos un modelo que logre mayor expresividad, con 2 capas LSTM, con más neuronas:\n"
   ],
   "metadata": {
    "id": "JGIIzSLiFQ8-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_complex = Sequential()\n",
    "\n",
    "# Codificación one-hot\n",
    "model_complex.add(TimeDistributed(\n",
    "    CategoryEncoding(num_tokens=vocab_size, output_mode=\"one_hot\"),\n",
    "    input_shape=(None, 1)\n",
    "))\n",
    "\n",
    "# Primera capa LSTM potente\n",
    "model_complex.add(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "# Segunda capa LSTM más liviana\n",
    "model_complex.add(LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "model_complex.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model_complex.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model_complex.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "P9j76-NgZrbL",
    "outputId": "5220c902-f8b3-47f5-ee27-cee990d69b5a"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mTimeDistributed\u001B[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)      │       \u001B[38;5;34m210,400\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)      │       \u001B[38;5;34m120,400\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m)       │         \u001B[38;5;34m6,262\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">210,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,262</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m337,062\u001B[0m (1.29 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337,062</span> (1.29 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m337,062\u001B[0m (1.29 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">337,062</span> (1.29 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name_complex = \"biblia_model_complex.keras\""
   ],
   "metadata": {
    "id": "piw7vUYkc7TA"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history_ppl_complex = []\n",
    "hist = model_complex.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val, history_ppl_complex, model_name_complex)], batch_size=256)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "breY2hOJc-5c",
    "outputId": "210bc8db-3a29-47ce-bd92-da1e17fce345"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556ms/step - loss: 3.0068\n",
      " mean perplexity: 10.722196329723705 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m526s\u001B[0m 661ms/step - loss: 3.0065\n",
      "Epoch 2/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552ms/step - loss: 2.2827\n",
      " mean perplexity: 8.041345803304152 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m556s\u001B[0m 657ms/step - loss: 2.2826\n",
      "Epoch 3/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552ms/step - loss: 2.0611\n",
      " mean perplexity: 7.139607877081091 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m562s\u001B[0m 657ms/step - loss: 2.0611\n",
      "Epoch 4/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551ms/step - loss: 1.9427\n",
      " mean perplexity: 6.657451468164271 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m556s\u001B[0m 650ms/step - loss: 1.9427\n",
      "Epoch 5/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556ms/step - loss: 1.8524\n",
      " mean perplexity: 6.248661683906208 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m571s\u001B[0m 661ms/step - loss: 1.8524\n",
      "Epoch 6/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 554ms/step - loss: 1.7793\n",
      " mean perplexity: 5.925464209643278 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m561s\u001B[0m 660ms/step - loss: 1.7793\n",
      "Epoch 7/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551ms/step - loss: 1.7205\n",
      " mean perplexity: 5.694614764777097 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m556s\u001B[0m 652ms/step - loss: 1.7205\n",
      "Epoch 8/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 559ms/step - loss: 1.6704\n",
      " mean perplexity: 5.519639964537187 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m568s\u001B[0m 660ms/step - loss: 1.6704\n",
      "Epoch 9/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 564ms/step - loss: 1.6262\n",
      " mean perplexity: 5.421613768014041 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m518s\u001B[0m 666ms/step - loss: 1.6262\n",
      "Epoch 10/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 562ms/step - loss: 1.5883\n",
      " mean perplexity: 5.35101687041196 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m560s\u001B[0m 663ms/step - loss: 1.5883\n",
      "Epoch 11/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 561ms/step - loss: 1.5529\n",
      " mean perplexity: 5.179659454389052 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 666ms/step - loss: 1.5528\n",
      "Epoch 12/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 555ms/step - loss: 1.5231\n",
      " mean perplexity: 5.16291559826244 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m514s\u001B[0m 661ms/step - loss: 1.5231\n",
      "Epoch 13/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551ms/step - loss: 1.4950\n",
      " mean perplexity: 5.094598495960236 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m559s\u001B[0m 657ms/step - loss: 1.4949\n",
      "Epoch 14/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 555ms/step - loss: 1.4685\n",
      " mean perplexity: 5.0561735955151645 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m560s\u001B[0m 654ms/step - loss: 1.4685\n",
      "Epoch 15/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 551ms/step - loss: 1.4452\n",
      " mean perplexity: 4.971992869810625 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m507s\u001B[0m 651ms/step - loss: 1.4452\n",
      "Epoch 16/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 552ms/step - loss: 1.4247\n",
      " mean perplexity: 4.938474225997925 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m511s\u001B[0m 657ms/step - loss: 1.4247\n",
      "Epoch 17/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558ms/step - loss: 1.4047\n",
      " mean perplexity: 4.977944538268176 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m563s\u001B[0m 659ms/step - loss: 1.4047\n",
      "Epoch 18/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556ms/step - loss: 1.3852\n",
      " mean perplexity: 4.943906111066991 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m564s\u001B[0m 662ms/step - loss: 1.3852\n",
      "Epoch 19/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 558ms/step - loss: 1.3687\n",
      " mean perplexity: 4.863756505467675 \n",
      "\n",
      "Saved new model!\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m560s\u001B[0m 659ms/step - loss: 1.3687\n",
      "Epoch 20/20\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581ms/step - loss: 1.3539\n",
      " mean perplexity: 4.911314532431689 \n",
      "\n",
      "\u001B[1m778/778\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m583s\u001B[0m 686ms/step - loss: 1.3539\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Entrenamiento\n",
    "epoch_count = range(1, len(history_ppl_complex) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl_complex)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "bzAxG47pF5jx",
    "outputId": "9830a1c2-2e59-4ec6-b292-96386e32d7f8"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "El entrenamiento fue constante y progresivo, lográndose además el mejor resultado en pérdida."
   ],
   "metadata": {
    "id": "KLDENdc1JgKI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_complex = keras.models.load_model(model_name_complex)"
   ],
   "metadata": {
    "id": "2W7s_FeaGJey"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_seq(model_complex, input_text_1, max_length=max_context_size, n_tokens=100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "34hyccziJwuA",
    "outputId": "0e0bd42c-1ddb-4265-968c-10fa40529134"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'y entonces moisés a moisés: «¿que se ha de la tienda del encuentro de la tienda del encuentro de la tienda del encuent'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "salidas = beam_search(model_complex, num_beams=10, num_tokens=100, input=input_text_1)\n",
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJcfERoQJ8RI",
    "outputId": "8c3f578a-5d87-4808-847c-0df4403d440a"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la tienda del\n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de los israelita\n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la tierra de \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la tienda de \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la comunidad \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la morada de \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de los hijos de \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de sus hijos de \n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro de la tierra del\n",
      "y entonces moisés habló yahveh había mandado a moisés: «¿quedará impuro hasta la tienda del encuentro del altar de la \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "salidas_sto = beam_search(model_complex, num_beams=10, num_tokens=100, input=input_text_1, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlaIOaFWKDoi",
    "outputId": "abfa96bd-7d64-47d0-8e83-853b3dcca1e6"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y quedar\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y quedas\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y que ha\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y quedak\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y que é5\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y quedas\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y que po\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y queda \n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y que ya\n",
      "y entonces moisés así moisés: «¿podréis que yos diciendo: [1] y a aarón y se lo había moisés: «¿por escarlata y quedal\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(generate_seq(model_complex, input_text_2, max_length=max_context_size, n_tokens=150))\n",
    "salidas = beam_search(model_complex, num_beams=10, num_tokens=150, input=input_text_2)\n",
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)\n",
    "salidas_sto = beam_search(model_complex, num_beams=10, num_tokens=150, input=input_text_2, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEKWZ73pbOrU",
    "outputId": "d86bc4e8-8d47-4210-d8d9-a3a305144bad"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro d\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tien\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro, el sacerd\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro del altar \n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de los isr\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro del altar.\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la mora\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tier\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro del altar,\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de sus hij\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, por el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de la tienda del encuentro de los hij\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la cierd\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comuc\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comun\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comer\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la cierr\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la ciern\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comer\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la cierz\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comer\n",
      "y descendió fuego del cielo, y consumió el altar y el sacrificio, comerás los israelitas y será el pueblo. [12] las propiaciós de garaón y los israelitas, se triban los hijos. [25] así lo meriba la morada de la comet\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(generate_seq(model_complex, input_text_3, max_length=max_context_size, n_tokens=40))\n",
    "salidas = beam_search(model_complex, num_beams=10, num_tokens=40, input=input_text_3)\n",
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)\n",
    "salidas_sto = beam_search(model_complex, num_beams=10, num_tokens=40, input=input_text_3, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BUbBSRsb7v3",
    "outputId": "7fb8df51-492e-4e90-cf61-0a3a0b92aba0"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y habló dios, diciendo a moisés: «¿que se ha de la tienda del e\n",
      "y habló dios, diciendo a los israelitas de la tienda del encuen\n",
      "y habló dios, diciendo a los israelitas de los israelitas de la\n",
      "y habló dios, diciendo a los israelitas de los israelitas en el\n",
      "y habló dios, diciendo a los israelitas de los israelitas de lo\n",
      "y habló dios, diciendo a los israelitas y los israelitas de la \n",
      "y habló dios, diciendo a los israelitas de los israelitas y los\n",
      "y habló dios, diciendo a los israelitas de los israelitas de su\n",
      "y habló dios, diciendo a los israelitas de los israelitas y el \n",
      "y habló dios, diciendo a los israelitas de la tienda del encuer\n",
      "y habló dios, diciendo a los israelitas de los israelitas en la\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su pu\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su ia\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su pr\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su da\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con la po\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con la sa\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con la pi\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su os\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con la pe\n",
      "y habló dios, diciendo a moisés: [3] harás a moisés: «con su or\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(generate_seq(model_complex, input_text_4, max_length=max_context_size, n_tokens=100))\n",
    "salidas = beam_search(model_complex, num_beams=10, num_tokens=100, input=input_text_4)\n",
    "salidas_decoded = [decode(salida) for salida in salidas]\n",
    "for salida in salidas_decoded:\n",
    "    print(salida)\n",
    "salidas_sto = beam_search(model_complex, num_beams=10, num_tokens=100, input=input_text_4, temp=2, mode='sto')\n",
    "salidas_sto_decoded = [decode(salida) for salida in salidas_sto]\n",
    "for salida in salidas_sto_decoded:\n",
    "    print(salida)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgmempiqb_Kb",
    "outputId": "1dc5f6e1-c4b6-405c-eaa6-55eaca107fde"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y sus hijos de la morada de la tienda del encuentro de la tienda del encuentro de la tienda del encuen\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del e\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de los israelitas \n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de los israelitas,\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de los israelitas.\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tierra de la\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro, el sacerdote lo q\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro, el sacerdote los \n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda de la\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de los israelitas;\n",
      "y el sacrificio por el pecado de la tienda del encuentro de la tienda del encuentro de la tienda del a\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país u\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país; \n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país h\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país c\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país s\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su paí vl\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país o\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su país t\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su paíse.\n",
      "y moisés siete muerta por las holacaustos descarseros y que el bueblo y comerán uno mano con su paíse \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aunque se pueden evidenciar algunas mejoras con respecto a las anteriores alternativas propuestas, se vuelven a repetir los mismos problemas y las palabras utilizadas por este modelo son muy similares así como los problemas de semántica, e incluso se repite la problemática de la invensión de palabras inexistentes cuando se utiliza una temperatura de 2 con generación estocástica."
   ],
   "metadata": {
    "id": "A_eVFq8QJ2HE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparación de modelos\n",
    "\n",
    "Finalmente, comparemos las métricas pérdida (`loss`) y `perplexity` media:\n",
    "\n",
    "| Modelo                            | Arquitectura principal                  | Loss   | Mean Perplexity |\n",
    "|-----------------------------------|-----------------------------------------|--------|------------------|\n",
    "| **1. SimpleRNN (baseline)**       | One-hot + SimpleRNN(200)                | 1.4100 | 4.8024           |\n",
    "| **2. GRU + Embedding**            | Embedding + GRU(64)                     | 1.4793 | 5.8841           |\n",
    "| **3. LSTM (ligero)**              | One-hot + LSTM(128)                     | 1.5272 | 5.5143           |\n",
    "| **4. LSTM (doble capa)**       | One-hot + LSTM(200) + LSTM(100)         | 1.3539 | 4.9113           |\n",
    "\n",
    "- El **modelo 4**, con doble capa LSTM obtuvo el **mejor resultado en términos de pérdida (`loss`)**, lo cual indica que se ajustó mejor a los datos de entrenamiento.\n",
    "- El **modelo 1** (SimpleRNN), aunque más simple, logró la **mejor `perplexity` media**, si consideramos el menor valor como mejor, dentro del rango entre 4 y 6. Esto sugiere que es un modelo muy competitivo pese a su arquitectura básica.\n",
    "- El **modelo 2**, basado en `GRU` con `Embedding`, tuvo el rendimiento bajo. Esto podría deberse a que un vocabulario pequeño (62) no se beneficia tanto de embeddings, y las GRU con pocas unidades pueden no capturar patrones suficientes.\n",
    "- El **modelo 3**, un `LSTM` ligero, también quedó por detrás, pero cerca del modelo GRU.\n",
    "\n",
    "### Próximos pasos\n",
    "\n",
    "Continuar experimentando con el **modelo 4**, variando unidades, dropout, o cantidad de capas."
   ],
   "metadata": {
    "id": "okJUCfs4Bmug"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python (npl)",
   "name": "npl",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
